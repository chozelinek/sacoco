<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Universität des Saarlandes" />

<meta name="date" content="2016-01-29" />

<title>Saarbrücken Cookbook Corpus: a recipe for a diachronic study à la CLARIN-D</title>

<script src="index_files/jquery-1.11.3/jquery.min.js"></script>
<script src="index_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="index_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="index_files/tocify-1.9.1/jquery.tocify.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="index_files/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="index_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="index_files/bootstrap-3.3.5/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; background-color: #dddddd; }
td.sourceCode { padding-left: 5px; }
code > span.kw { font-weight: bold; } /* Keyword */
code > span.dt { color: #800000; } /* DataType */
code > span.dv { color: #0000ff; } /* DecVal */
code > span.bn { color: #0000ff; } /* BaseN */
code > span.fl { color: #800080; } /* Float */
code > span.ch { color: #ff00ff; } /* Char */
code > span.st { color: #dd0000; } /* String */
code > span.co { color: #808080; font-style: italic; } /* Comment */
code > span.al { color: #00ff00; font-weight: bold; } /* Alert */
code > span.fu { color: #000080; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #ff0000; font-weight: bold; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #ff00ff; } /* SpecialChar */
code > span.vs { color: #dd0000; } /* VerbatimString */
code > span.ss { color: #dd0000; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { font-weight: bold; } /* Preprocessor */
code > span.at { } /* Attribute */
code > span.do { color: #808080; font-style: italic; } /* Documentation */
code > span.an { color: #808080; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #808080; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #808080; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>
<div class="container-fluid main-container">

<!-- tabsets -->
<script src="index_files/navigation/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {
    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: "h1.title, .toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">


<h1 class="title">Saarbrücken Cookbook Corpus: a recipe for a diachronic study <em>à la CLARIN-D</em></h1>
<h4 class="author"><em>Universität des Saarlandes</em></h4>
<h4 class="date"><em>29 January 2016</em></h4>

</div>


<p><a href="http://hdl.handle.net/11858/00-246C-0000-001F-7C43-1"><img src="index_files/img/sacoco-logo.png" title="Saarbrücken Cookbook Corpus&#39; logo" alt="sacoco logo" /></a></p>
<p>This tutorial will show you step-by-step how to use the CLARIN-D infrastructure to compile a diachronic corpus of German cooking recipes. Afterwards, you will learn how to exploit this resource to discover how the conative function has evolved in this register during the last centuries.</p>
<p>In order to reproduce successfully this showcase, you will need to satisfy the following requirements:</p>
<ul>
<li>a Mac, Linux, Windows operative system (tested on Mac OS X, Linux Ubuntu)</li>
<li><a href="http://www.xmlsoft.org/downloads.html">libxml2 and libxslt</a></li>
<li>7z</li>
<li>Python 3, and some packages (<code>pip3 install -r requirements.txt</code>)
<ul>
<li>lxml</li>
<li>pandas</li>
<li>regex</li>
<li>requests</li>
</ul></li>
<li>R, and some packages
<ul>
<li>reshape2</li>
<li>dplyr</li>
<li>ggplot2</li>
</ul></li>
<li>internet connection</li>
</ul>
<p>You also need the materials. Go to our GitHub <a href="https://github.com/chozelinek/sacoco">repo</a> and clone it.</p>
<p>Ready? Steady! Go!</p>
<div id="corpus-compilation" class="section level1">
<h1>Corpus compilation</h1>
<p>A corpus is a collection of texts in electronic format. We distinguish three main steps in the process of compiling an electronic corpus:</p>
<ol style="list-style-type: decimal">
<li>data acquisition and preprocessing</li>
<li>linguistic annotation with WebLicht</li>
<li>corpus encoding for CQPweb</li>
</ol>
<p>We have two different sources of data:</p>
<ul>
<li>contemporary</li>
<li>historical</li>
</ul>
<p>The <strong>historical</strong> recipes were transcribed and digitised manually by Andrea Wurm. We complemented this data set with some transcriptions done by Glonning et al.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. In parallel, we obtained a set of <strong>contemporary</strong> recipes from a wiki site devoted to cooking recipes <a href="http://www.kochwiki.org/wiki/Hauptseite">kochwiki.org</a>. Luckily, a XML dump of this site is available at the <a href="https://archive.org/download/wiki-rezeptewikiorg">Internet Archive</a>.</p>
<p>Due to the different nature of our historical and contemporary datasets. The corpus compilation methodology although following a similar outline is slightly different.</p>
<div id="data-acquisition-and-preprocessing" class="section level2 tabset tabset-fade tabset-pills">
<h2>Data acquisition and preprocessing</h2>
<p>Our goal at this stage is to obtain the data in digital form. And afterwards, preprocess the material to obtain a homogeneous minimalist TEI/XML format, that we can easily integrate in our pipeline, namely: WebLicht and CQP.</p>
<div id="contemporary-data" class="section level3">
<h3>Contemporary data</h3>
<p>Download a wiki dump from <a href="https://archive.org/download/wiki-rezeptewikiorg" class="uri">https://archive.org/download/wiki-rezeptewikiorg</a>. The file to be downloaded from the archive is 19.8M and gets huge when extracted (1.21G). That’s the reason why we don’t include it. The GitHub repository you downloaded includes a smaller test file, so you don’t have to download the original file for testing, if you don’t want to.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># dowload the dump to the data/contemporary/source folder</span>
<span class="kw">wget</span> -P data/contemporary/source https://archive.org/download/wiki-rezeptewikiorg/rezeptewikiorg-20140325-history.xml.7z
<span class="co"># unzip the file</span>
<span class="kw">7z</span> x -odata/contemporary/source data/contemporary/source/rezeptewikiorg-20140325-history.xml.7z rezeptewikiorg-20140325-history.xml</code></pre></div>
<blockquote>
<p>TIP: if you are just testing, you can skip this step. You can find an excerpt of this file in the <code>test/conteporary/source/</code> folder.</p>
</blockquote>
<p>The size of the extracted file can give you a slight idea of the daunting task of extracting information manually from this file. Thus, we use a python script instead (<code>wikiextractor.py</code>) to automatically structure the data and extract the following information:</p>
<ul>
<li>a minimal <strong>TEI/XML</strong> file for each recipe containing:
<ul>
<li>title, and</li>
<li>cooking instructions (only the section where the actual cooking procedure is described, no comments, no history of the dish…)</li>
</ul></li>
<li>a CSV file containing metadata for each page such as:
<ul>
<li>authors</li>
<li>ingredients</li>
<li>tools</li>
<li>methods</li>
<li>cuisines</li>
<li>URL</li>
</ul></li>
</ul>
<p>The input for this script is the huge file <code>rezeptewikiorg-20140325-history.xml</code>. It contains thousands of <code>page</code> nodes, their <code>revisions</code> and the actual <code>texts</code>. See an example page below.</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;page&gt;</span>
  <span class="kw">&lt;title&gt;</span><span class="dv">&amp;quot;</span>Krömpele<span class="dv">&amp;quot;</span>-Suppe<span class="kw">&lt;/title&gt;</span>
  <span class="kw">&lt;ns&gt;</span>0<span class="kw">&lt;/ns&gt;</span>
  <span class="kw">&lt;id&gt;</span>46526<span class="kw">&lt;/id&gt;</span>
  <span class="kw">&lt;sha1&gt;</span>rhhwusxi5j205lgcktz71ncz5s12gwu<span class="kw">&lt;/sha1&gt;</span>
  <span class="kw">&lt;revision&gt;</span>
    <span class="kw">&lt;id&gt;</span>262379<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;timestamp&gt;</span>2013-10-30T15:27:50Z<span class="kw">&lt;/timestamp&gt;</span>
    <span class="kw">&lt;contributor&gt;</span>
      <span class="kw">&lt;username&gt;</span>CTHOE<span class="kw">&lt;/username&gt;</span>
      <span class="kw">&lt;id&gt;</span>927<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;/contributor&gt;</span>
    <span class="kw">&lt;comment&gt;</span>Neu angelegt<span class="kw">&lt;/comment&gt;</span>
    <span class="kw">&lt;text</span><span class="ot"> xml:space=</span><span class="st">&quot;preserve&quot;</span><span class="ot"> bytes=</span><span class="st">&quot;1851&quot;</span><span class="kw">&gt;</span>{{Rezept|
 | Menge         = 4 Personen
 | Zeit          = 30–40 Minuten
 | Schwierigkeit = leicht
 | Alkohol       = nein
 | Vegetarisch   = nein
 | Bild          = Kein_Bild.png
|}}

== Zutaten ==
* 175 g [[Zutat:Mehl|Mehl]], gesiebt
* 2–3 [[Zutat:Ei|Eier]]
* 1 Pr. [[Zutat:Salz|Salz]]
* 500 ml [[Zutat:Fleischbrühe|Fleischbrühe]]
* 250 g [[Zutat:Schinkenspeck|Schinkenspeck]]
* frisch geriebener [[Zutat:Muskat|Muskat]]
* 2–3 EL [[Zutat:Schnittlauch|Schnittlauch]]

== Kochgeschirr ==
* 1 [[Zubereitung:Küchenbrett|Küchenbrett]]
* 1 [[Zubereitung:Topf|Topf]]
* 1 [[Zubereitung:Pfanne|Pfanne]]

== Zubereitung ==
* Schnittlauch in kleine Röllchen [[Zubereitung:schneiden|schneiden]]
* Gewürze, Mehl und Eier mit etwas Wasser zu einem dickflüssigen Teig verrühren
* Unter Umständen muss etwas Mehl oder Wasser dazugegeben werden, um die richtige Konsistenz des Teiges zu erreichen
* Den Teig zu großen &#39;&#39;Krömpele&#39;&#39; (Krümel) mit den Händen verreiben
* Etwa 1 l Wasser mit der Brühe [[Zubereitung:aufkochen|aufkochen]]
* Hierin die &#39;&#39;Krömpele&#39;&#39; leicht [[Zubereitung:köcheln|köchelnd]] in etwa 15 Minuten [[Zubereitung:garziehen|garziehen]] lassen
* Zwischenzeitlich den Speck fein [[Zubereitung:würfeln|würfeln]] und goldbraun [[Zubereitung:ausbraten|ausbraten]]
* Speckwürfel in die Suppe schütten, [[Zubereitung:abschmecken|abschmecken]] und mit reichlich Schnittlauchröllchen [[Zubereitung:garnieren|garnieren]] und [[Zubereitung:anrichten|anrichten]]

[[Kategorie:Thüringer Küche]]
[[Kategorie:Nocken]]
[[Kategorie:Vorspeisen]]
[[Kategorie:Suppen]]<span class="kw">&lt;/text&gt;</span>
  <span class="kw">&lt;/revision&gt;</span>
<span class="kw">&lt;/page&gt;</span>  </code></pre></div>
<p>The script does the following:</p>
<ol style="list-style-type: decimal">
<li>opens the input XML file</li>
<li>gets all <code>page</code> nodes</li>
<li>filters those recipes corresponding to German speaking regions only</li>
<li>for each of those recipes gets the last revision</li>
<li>extracts:
<ol style="list-style-type: decimal">
<li>revision ID</li>
<li>page ID</li>
<li>year of last revision</li>
<li>cuisine</li>
<li>authors</li>
<li>ingredients</li>
<li>tools</li>
<li>methods</li>
<li>title</li>
<li>text with the instructions</li>
</ol></li>
<li>title and text are saved as a TEI XML file (<code>data/contemporary/tei</code>)</li>
<li>metadata are saved in a CSV file (<code>data/metadata/contemporary-metadata.csv</code>)</li>
</ol>
<p>To run the script you need to run the following commands from the terminal:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># run the script</span>
<span class="kw">python3</span> wikiextractor.py -i data/contemporary/source/rezeptewikiorg-20140325-history.xml -x data/contemporary/tei -m data/metadata</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 wikiextractor.py</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
<p>An example for the result TEI files is <code>wiki_188908.xml</code> given below (I would include this as an example in the test directory, also a sample metadata file):</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;?xml-model</span> href=&quot;http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_lite.rng&quot; type=&quot;application/xml&quot; schematypens=&quot;http://relaxng.org/ns/structure/1.0&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;TEI</span><span class="ot"> xmlns=</span><span class="st">&quot;http://www.tei-c.org/ns/1.0&quot;</span><span class="ot"> xml:lang=</span><span class="st">&quot;de&quot;</span><span class="kw">&gt;</span>
  <span class="kw">&lt;teiHeader&gt;</span>
    <span class="kw">&lt;fileDesc&gt;</span>
      <span class="kw">&lt;titleStmt&gt;</span>
        <span class="kw">&lt;title&gt;</span>Räucherfischmousse im Knusperröllchen auf Gurken-Rahmsalat<span class="kw">&lt;/title&gt;</span>
        <span class="kw">&lt;author&gt;</span>Qualia, Jozeil, NikiWiki<span class="kw">&lt;/author&gt;</span>
        <span class="kw">&lt;respStmt&gt;</span>
          <span class="kw">&lt;resp/&gt;</span>
          <span class="kw">&lt;name/&gt;</span>
        <span class="kw">&lt;/respStmt&gt;</span>
      <span class="kw">&lt;/titleStmt&gt;</span>
      <span class="kw">&lt;publicationStmt&gt;</span>
        <span class="kw">&lt;publisher&gt;</span>Universität des Saarlandes<span class="kw">&lt;/publisher&gt;</span>
        <span class="kw">&lt;pubPlace&gt;</span>Saarbrücken<span class="kw">&lt;/pubPlace&gt;</span>
        <span class="kw">&lt;availability</span><span class="ot"> status=</span><span class="st">&quot;free&quot;</span><span class="kw">&gt;</span>
          <span class="kw">&lt;p&gt;</span>Published under a <span class="kw">&lt;ref</span><span class="ot"> target=</span><span class="st">&quot;http://creativecommons.org/licenses/by-sa/3.0/&quot;</span><span class="kw">&gt;</span>Creative Commons Attribution ShareAlike 3.0 License<span class="kw">&lt;/ref&gt;</span>.<span class="kw">&lt;/p&gt;</span>
        <span class="kw">&lt;/availability&gt;</span>
        <span class="kw">&lt;date&gt;</span>2016<span class="kw">&lt;/date&gt;</span>
      <span class="kw">&lt;/publicationStmt&gt;</span>
      <span class="kw">&lt;sourceDesc&gt;</span>
        <span class="kw">&lt;p&gt;</span>http://www.kochwiki.org/w/index.php?oldid=188908<span class="kw">&lt;/p&gt;</span>
      <span class="kw">&lt;/sourceDesc&gt;</span>
    <span class="kw">&lt;/fileDesc&gt;</span>
  <span class="kw">&lt;/teiHeader&gt;</span>
  <span class="kw">&lt;text</span><span class="ot"> xml:id=</span><span class="st">&quot;wiki-188908&quot;</span><span class="kw">&gt;</span>
    <span class="kw">&lt;body&gt;</span>
      <span class="kw">&lt;div</span><span class="ot"> n=</span><span class="st">&quot;1&quot;</span><span class="ot"> type=</span><span class="st">&quot;recipe&quot;</span><span class="kw">&gt;</span>
        <span class="kw">&lt;head&gt;</span>Räucherfischmousse im Knusperröllchen auf Gurken-Rahmsalat<span class="kw">&lt;/head&gt;</span>
        <span class="kw">&lt;div</span><span class="ot"> n=</span><span class="st">&quot;2&quot;</span><span class="ot"> type=</span><span class="st">&quot;contents&quot;</span><span class="kw">&gt;</span>
          <span class="kw">&lt;head&gt;</span>Räucherfischmousse<span class="kw">&lt;/head&gt;</span>
          <span class="kw">&lt;p&gt;</span>Das Saiblingsfilet entgräten und in grobe Stücke schneiden. Den Fischfond in einem Topf aufkochen. Die Speisestärke in wenig Wasser glatt rühren, den Fond damit abbinden und auskühlen lassen. Dann die Flüssigkeit mit den Räucherfischstücken in den Mixaufsatz der Küchenmaschine füllen und pürieren &quot;(Falls kein Mixaufsatz oder Küchenmaschine vorhanden einen Zauberstab verwenden)&quot;. Die Gelatine in kaltem Wasser einweichen. Einen Topf mit zwei EL Wasser erwärmen und die gut ausgedrückte Gelatine darin auflösen. Während dessen die Schlagsahne halb fest aufschlagen. Die Fischmasse in eine Schüssel füllen und mit der Gelatine sowie etwa der Hälfte des Schlagobers gut vermengen. Dann die restliche Schlagsahne locker unterheben. Das Räucherfischmousse mit Salz sowie Pfeffer abschmecken. Die fertige Fischfüllung mit Klarsichtfolie abdecken und für mindestens 1/2 Stunde im Kühlschrank kalt stellen.<span class="kw">&lt;/p&gt;</span>
        <span class="kw">&lt;/div&gt;</span>
      <span class="kw">&lt;/div&gt;</span>
    <span class="kw">&lt;/body&gt;</span>
  <span class="kw">&lt;/text&gt;</span>
<span class="kw">&lt;/TEI&gt;</span></code></pre></div>
<p>And this is just an example of a few instances of the metadata file:</p>
<table style="width:50%;">
<colgroup>
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">source</th>
<th align="left">year</th>
<th align="left">title</th>
<th align="left">authors</th>
<th align="left">categories</th>
<th align="left">ingredients</th>
<th align="left">methods</th>
<th align="left">tools</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">wiki-142256</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Salziger Wähenteig mit saurer Sahne</td>
<td align="left">Vran01, Jozeil</td>
<td align="left">Schweizer Küche</td>
<td align="left">Sahne, Salz, Mehl, Butter</td>
<td align="left"></td>
<td align="left">Schüssel, Küchenwaage, Frischhaltefolie</td>
</tr>
<tr class="even">
<td align="left">wiki-150044</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Punschglasur</td>
<td align="left">Jozeil</td>
<td align="left">Österreichische Küche</td>
<td align="left">Eiweiß, Zucker, Orangensaft, Rum</td>
<td align="left">Glasieren</td>
<td align="left">Schüssel, Schneebesen</td>
</tr>
<tr class="odd">
<td align="left">wiki-158731</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Riebelesuppe</td>
<td align="left">Vran01, Hombre, Jozeil, Daniel Beyer</td>
<td align="left">Schwäbische Küche</td>
<td align="left">Weizenmehl, Brühwürfel, Ei, Salz, Pfeffer, Meersalz</td>
<td align="left">Abschmecken</td>
<td align="left">Schüssel, Topf, Küchenreibe</td>
</tr>
</tbody>
</table>
<p>You can check from the command line if the TEI files are alright:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in data/contemporary/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, just switch the input folder:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in test/contemporary/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
</div>
<div id="historical-data" class="section level3">
<h3>Historical data</h3>
<p>We take as starting point the materials in <code>data/historical/source</code>. Our goal is to generate a TEI Lite XML for each recipe, and extract the metadata.</p>
<p>The script <code>xmlextractor.py</code> will help us with the task of normalizing our data.</p>
<p><code>xmlextractor.py</code>:</p>
<ol style="list-style-type: decimal">
<li>gets all XML files in the input folder</li>
<li>for each file
<ol style="list-style-type: decimal">
<li>extracts metadata:
<ol style="list-style-type: decimal">
<li>text ID</li>
<li>year</li>
<li>authors</li>
<li>source</li>
<li>title</li>
<li>text with the instructions</li>
</ol></li>
<li>clean the text from previous annotation</li>
<li>adds source and appropriate license to the text</li>
<li>title and text are saved as a TEI XML file (<code>data/historical/tei</code>)</li>
<li>metadata are saved in a CSV file (<code>data/metadata/historical-metadata.csv</code>)</li>
</ol></li>
</ol>
<p>To run the script you need to run the following commands from the terminal:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># run the script</span>
<span class="kw">python3</span> xmlextractor.py -i data/historical/source -x data/historical/tei -m data/metadata</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 xmlextractor.py</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
<p>You can check from the command line if the TEI files are alright:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in data/historical/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, just switch the input folder:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in test/historical/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
</div>
</div>
<div id="data-processing-with-weblicht" class="section level2">
<h2>Data processing with WebLicht</h2>
<p>In the previous section, we have seen how to <em>shape</em> our data. Once that we have a homogeneous format for both collections, we can start to process the texts with <a href="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/Main_Page"><strong>WebLicht</strong></a>.</p>
<p>We have to process the two collections (historical and contemporary) separately in WebLicht as we need two slightly different pipelines. In both cases, we have to perform the following steps:</p>
<ol style="list-style-type: decimal">
<li>design a chain in WebLicht
<ol style="list-style-type: decimal">
<li>authenticate</li>
<li>build a tool chain</li>
</ol></li>
<li>process all recipes with this chain using WaaS (WebLicht as a Service)
<ol style="list-style-type: decimal">
<li>get an API key for WaaS</li>
<li>use a python wrapper to interact with WebLicht</li>
</ol></li>
</ol>
<div id="logging-into-weblicht" class="section level3">
<h3>Logging into WebLicht</h3>
<p>We use the Shibboleth Authentication service to log in WebLicht. We will need an identity from a CLARIN identity provider. If your institution is not such a provider you can request an account from the CLARIN provider.</p>
<ol style="list-style-type: decimal">
<li>Visit the <a href="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/Main_Page">WebLicht Wiki</a>, scroll down to the bottom of the page and click on the blue button to <code>Start WebLicht</code>.</li>
<li>The Shibboleth Authentication service will load. Choose your identity provider (<code>clarin.eu website account</code> if you are using a CLARIN account).</li>
<li>You will be redirected to an institutional page where you have to provide your user and password.</li>
<li>If everything is OK, WebLicht’s welcome page will be loaded.</li>
</ol>
<p>This video prepared by our colleagues at Tübingen precisely illustrate the logging process:</p>
<video width="640" height="360" autobuffer controls preload="auto">
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.mp4" type="video/mp4"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.ogv" type="video/ogg"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.webm" type="video/webm"/>
</video>
<p>If you run into problems, read the <a href="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/FAQ#Logging_In">FAQ explaining how to loggin into WebLicht</a>.</p>
</div>
<div id="building-the-tool-chain-to-process-the-data" class="section level3 tabset tabset-fade tabset-pills">
<h3>Building the tool chain to process the data</h3>
<div id="contemporary-tool-chain" class="section level4">
<h4>Contemporary tool chain</h4>
<ol style="list-style-type: decimal">
<li>Click on <code>New Chain</code>.</li>
<li>A window will pop-up.</li>
<li>There are 3 input modes: click on the rightmost button <code>Browse</code>.</li>
<li>Choose <code>utils/tcf_example.xml</code>.</li>
<li>Click on OK.</li>
<li>Choose the tools:
<ol style="list-style-type: decimal">
<li>Berlin: Tokenizer and Sentence</li>
<li>Berlin: Part-of-Speech Tagger</li>
</ol></li>
<li>Download the chain by clicking on <code>Download chain</code></li>
<li>Save the XML file as <code>chain_contemporary.xml</code> in the folder <code>utils</code> of our repository.</li>
</ol>
<p>For information on how to design a tool chain you can also watch the following video.</p>
<video width="640" height="360" autobuffer controls preload="auto">
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.mp4" type="video/mp4"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.ogv" type="video/ogg"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.webm" type="video/webm"/>
</video>
</div>
<div id="historical-tool-chain" class="section level4">
<h4>Historical tool chain</h4>
<p>The process is exactly the same as we used before.</p>
<ol style="list-style-type: decimal">
<li>Click on <code>New Chain</code>.</li>
<li>A window will pop-up.</li>
<li>There are 3 input modes: click on the rightmost button <code>Browse</code>.</li>
<li>Choose <code>utils/tcf_example.xml</code>.</li>
<li>Click on OK.</li>
<li>Choose the tools:
<ol style="list-style-type: decimal">
<li>Berlin: Tokenizer and Sentence</li>
<li>Berlin: CAB historical text</li>
</ol></li>
<li>Download the chain by clicking on <code>Download chain</code></li>
<li>Save the XML file as <code>chain_historical.xml</code> in the folder <code>scripts</code> of our repository.</li>
</ol>
</div>
</div>
<div id="using-weblicht-as-a-service" class="section level3 tabset tabset-fade tabset-pills">
<h3>Using WebLicht as a service</h3>
<p>We could now process our texts directly through the user-friendly WebLicht GUI. However, if you have thousands of recipes to be annotated, it is more efficient to use <a href="https://weblicht.sfs.uni-tuebingen.de/WaaS/"><strong>WaaS</strong></a> (WebLicht as a Service) to execute our WebLicht chains.</p>
<blockquote>
<p>WebLicht as a Service (WaaS) is a REST service that executes WebLicht chains. This allows you to run WebLicht chains from your UNIX shell, scripts, or programs.</p>
</blockquote>
<p>It means that we can write a script to automatize our interaction with WebLicht!</p>
<p>We need at least two things:</p>
<ol style="list-style-type: decimal">
<li>a WebLicht chain</li>
<li>an API key (a kind of “password” to be passed to WaaS)</li>
</ol>
<p>We already have our WebLicht chains. For the second, go to the <a href="https://weblicht.sfs.uni-tuebingen.de/WaaS">WaaS home page</a>, click on the rightmost menu item at the top of the page called <code>API Key</code>. You will be redirected to the already familiar authentication page, choose your institution (<code>clarin.eu website account</code> for us), provide your credentials and a new page will load. If you hit on the button <code>Generate</code> a long string will appear where it reads <code>Your API key</code>. Copy the key in a safe place and treat it like it was a password.</p>
<p>Time to actually process our XML files with <code>WaaS</code>!</p>
<div id="contemporary-recipes" class="section level4">
<h4>Contemporary recipes</h4>
<p>We have created a python script to process the recipes with WaaS (<code>weblichtwrapper.py</code>).</p>
<p>The goal of the script is to process all TEI/XML files in a folder with WebLicht and save the results in VRT files for their encoding as a corpus for the Corpus WorkBench (CWB).</p>
<p>The input is typically a folder with the TEI/XML files we created in previous sections. But in fact we could use any XML file.</p>
<p>The script does the following:</p>
<ol style="list-style-type: decimal">
<li>gets a list of all files to be transformed</li>
<li>finds all nodes containing text to be processed</li>
<li>sends to WaaS a request to process the text of a node with the provided chain</li>
<li>converts the WaaS response in TCF format to VRT</li>
<li>saves the VRT files in the target directory</li>
</ol>
<p>To run the script you need to invoke the following commands from the terminal</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> waaswrapper.py -i data/contemporary/tei -c utils/chain_contemporary.xml -o data/contemporary/vrt</code></pre></div>
<p>Then, you will be prompted to provide your API key.</p>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 waaswrapper.py -t contemporary</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
<p>You can get more information on the parameters this script takes by running:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> waaswrapper.py -h</code></pre></div>
<p>The output is a VRT file (one token per line and positional attributes separated by a tabulation).</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;text</span><span class="ot"> id=</span><span class="st">&quot;wiki_244969&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;p&gt;</span>
<span class="kw">&lt;s&gt;</span>
Das ART d
Brot    NN  Brot
in  APPR    in
ca. ADV ca.
1   CARD    1
cm  NN  Cm
große   ADJA    groß
Würfel  NN  Würfel
schneiden   VVFIN   schneiden
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;s&gt;</span>
Die ART d
Sonnenblumenkerne   NN  Sonnenblumenkern
in  APPR    in
einer   ART eine
Pfanne  NN  Pfanne
ohne    APPR    ohne
Öl  NN  Öl
anrösten    VVINF   anrösten
und KON und
fein    ADJD    fein
reiben  VVINF   reiben
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;s&gt;</span>
Mit APPR    mit
Sonnenblumenkernen  NN  Sonnenblumenkern
,   $,  ,
Stachelbeeren   NN  Stachelbeere
sowie   KON sowie
Minze   NN  Minze
garnieren   VVINF   garnieren
und KON und
heiß    ADJD    heiß
servieren   VVINF   servieren
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;/p&gt;</span>
<span class="kw">&lt;/text&gt;</span></code></pre></div>
</div>
<div id="historical-recipes" class="section level4">
<h4>Historical recipes</h4>
<p>The procedure is exactly the same, the only differences are: the location of the input files, and the chain to be used.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> waaswrapper.py -i data/historical/tei -c utils/chain_historical.xml -o data/historical/vrt</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 waaswrapper.py -t historical</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
</div>
</div>
</div>
<div id="corpus-encoding-for-cqpweb" class="section level2">
<h2>Corpus encoding for CQPweb</h2>
<p>We are going to encode our corpus for the <a href="http://cwb.sourceforge.net">IMS Open Corpus WorkBench</a> (a tool initially developed at IMS Stuttgart). This tool will allow us to query the corpus making the most of the annotation we have obtained with WebLicht.</p>
<p>The CWB expects XML files where two kind of attributes can be added:</p>
<ul>
<li>structural (equivalent to XML attributes, and they affect to regions of tokens)</li>
<li>positional, to add multiple layers of information at token level</li>
</ul>
<p>In the previous section we created the VRT files with the required positional information. Now, we will complete the annotation by adding structural attributes to the text element from the metadata we stored in a CSV file.</p>
<p>We will have to prepare our data for the CQPweb through a series of very simple steps:</p>
<ol style="list-style-type: decimal">
<li>adding the metadata to the VRT files</li>
<li>generate a metadata file for the CQPweb</li>
</ol>
<div id="add-the-metadata-to-the-vrt-files" class="section level3 tabset tabset-fade tabset-pills">
<h3>Add the metadata to the VRT files</h3>
<p>To add the metadata as structural attributes we need:</p>
<ul>
<li>VRT files</li>
<li>metadata as CSV</li>
<li>a script (<code>addmetadata.py</code>)</li>
</ul>
<p><code>addmetadata.py</code>:</p>
<ol style="list-style-type: decimal">
<li>obtains of a list of all files to be transformed</li>
<li>parses the metadata</li>
<li>finds all nodes where the metadata fields will be added as attributes</li>
<li>adds to each node its corresponding metadata using the <code>text ID</code> as key</li>
<li>saves the VRT files in the target directory</li>
</ol>
<p>The output should look like this:</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;text</span><span class="ot"> id=</span><span class="st">&quot;wiki-200141&quot;</span><span class="ot"> year=</span><span class="st">&quot;2011&quot;</span><span class="ot"> period=</span><span class="st">&quot;2000&quot;</span><span class="ot"> authors=</span><span class="st">&quot;NikiWiki|Hombre|Jozeil&quot;</span><span class="ot"> decade=</span><span class="st">&quot;2010&quot;</span><span class="ot"> title=</span><span class="st">&quot;Bärlauchnockerl&quot;</span><span class="ot"> methods=</span><span class="st">&quot;hacken|Abschmecken|anrichten&quot;</span><span class="ot"> ingredients=</span><span class="st">&quot;Muskatnuss|Pfeffer|Sauerrahm|Salz|Schmand|Bärlauch|Gelatine&quot;</span><span class="ot"> collection=</span><span class="st">&quot;contemporary&quot;</span><span class="ot"> cuisines=</span><span class="st">&quot;Oberösterreichische Küche&quot;</span><span class="ot"> source=</span><span class="st">&quot;wiki&quot;</span><span class="ot"> tools=</span><span class="st">&quot;Küchenreibe|Schlagkessel|Schüssel|Frischhaltefolie|Schneidebrett|Löffel|Messer|Zauberstab|Küchenmaschine&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;p&gt;</span>
<span class="kw">&lt;s&gt;</span>
Den ART d
Bärlauch    NN  Bärlauch
fein    ADJD    fein
hacken  VVINF   hacken
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;/p&gt;</span>
<span class="kw">&lt;/text&gt;</span></code></pre></div>
<div id="add-metadata-to-the-contemporary-recipes" class="section level4">
<h4>Add metadata to the contemporary recipes</h4>
<p>We use <code>addmetadata.py</code> Python script by running the following command:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> addmetadata.py -i data/contemporary/vrt -m data/metadata/contemporary-metadata.csv -o data/contemporary/meta</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 addmetadata.py -t contemporary</code>, it will work on the testing dataset stored in the test folder.</p>
</blockquote>
</div>
<div id="add-metadata-to-the-historical-recipes" class="section level4">
<h4>Add metadata to the historical recipes</h4>
<p>We need to run the command also on the historical recipes indicating the corresponding metadata file, the location of the input files, and the path for the output.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> addmetadata.py -i data/historical/vrt -m data/metadata/historical-metadata.csv -o data/historical/meta</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 addmetadata.py -t historical</code>, it will work on the testing dataset stored in the test folder.</p>
</blockquote>
</div>
</div>
<div id="generate-the-metadata-file-for-cqpweb" class="section level3">
<h3>Generate the metadata file for CQPweb</h3>
<p>CQPweb helps us to calculate distributions across different subcorpora. Typically, this subcorpora are the result of splitting our corpus according to some variables contained in the metadata. To achieve this we only need to pass once a metadata file containing for each text the value of the fields we are interested in.</p>
<p>We have already generated two metadata tables:</p>
<ul>
<li>contemporary</li>
<li>historical</li>
</ul>
<p>We will merge them and will extract only those fields whose distributions shall be displayed in CQPweb, namely:</p>
<ul>
<li>year</li>
<li>decade</li>
<li>period</li>
<li>collection</li>
</ul>
<p>Moreover, we will add the source and the title of the recipe as a free text field (they won’t be used for the distributions).</p>
<p>To get this file we use the script <code>meta2cqpweb.py</code>.</p>
<p><code>meta2cqpweb.py</code>:</p>
<ul>
<li>gets all input files</li>
<li>for each file:
<ul>
<li>extracts relevant columns</li>
</ul></li>
<li>concatenate info from all files</li>
<li>saves the output as tab-separated plain text file</li>
</ul>
<p>We use the following command:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> metadata4cqpweb.py -i data/metadata/contemporary-metadata.csv data/metadata/historical-metadata.csv -o data/metadata/sacoco.meta -c year decade period collection source title</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 metadata4cqpweb.py</code>, it will work on the testing dataset stored in the test folder.</p>
</blockquote>
</div>
</div>
<div id="set-up-a-corpus-in-cqpweb" class="section level2">
<h2>Set up a corpus in CQPweb</h2>
<p>We have all materials needed to set up a corpus in CQPweb:</p>
<ul>
<li>the texts in VRT format</li>
<li>a metadata file</li>
</ul>
<p>You need now to have access to a CQPweb installation as administrator. There are different options to get CQPweb running listed in decreasing order of difficulty:</p>
<ul>
<li><a href="http://cwb.sourceforge.net/cqpweb.php#cqpweb">install your own CQPweb</a>:
<ul>
<li>in your computer, only you have access to the corpus</li>
<li>in a server, you can share it with other people</li>
<li>PROS:
<ul>
<li>you have maximum control</li>
<li>you can share with other people if it is installed in a server</li>
</ul></li>
<li>CONS:
<ul>
<li>difficult to install, you need expert knowledge to admin a LAMP stack (Apache, MySQL, PHP), check the <a href="http://cwb.sourceforge.net/files/CQPwebAdminManual.pdf">administrator’s manual</a></li>
</ul></li>
</ul></li>
<li>use <a href="http://cwb.sourceforge.net/cqpweb.php#inabox">CQPwebInABox</a>:
<ul>
<li>PROS:
<ul>
<li>no installation required, just run a Virtual Machine</li>
<li>its usage is well documented</li>
</ul></li>
<li>CONS:
<ul>
<li>you cannot share your corpus with others</li>
<li>resource intensive, you will be running a Virtual Machine</li>
<li>you will have to get familiar with <em>Lubuntu</em></li>
</ul></li>
</ul></li>
<li>use <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb">our CQPweb installation</a>:
<ul>
<li>PROS:
<ul>
<li>you don’t have to cope with this section</li>
<li>you can share your corpus with others</li>
</ul></li>
<li>CONS:
<ul>
<li>you have to give us the corpus and the metadata in the right format (but… wait! You have just learnt how to do it!)</li>
<li>we work together to <em>clarinify</em> the resource (not too bad either, see the section on <a href="#integration-of-the-resource-in-the-clarin-d-infrastructure"><em>clarinifying</em></a> a corpus).</li>
</ul></li>
</ul></li>
</ul>
<p>If you don’t fulfill all this requirements and/or you don’t have experience enough, do not worry. Just jump to the section on <a href="#integration-of-the-resource-in-the-clarin-d-infrastructure"><em>clarinifying</em></a> and leave the gory details for us.</p>
<p>Nevertheless, we document under a separate cover all the steps to get SaCoCo encoded and installed in CQPweb. Check <a href="cqpwebsetup.html">CQPweb setup tutorial</a>.</p>
</div>
<div id="integration-in-the-clarin-d-infrastructure" class="section level2">
<h2>Integration in the CLARIN-D infrastructure</h2>
<p>We have created our resource. Now, we can <em>clarinify</em> it by:</p>
<ul>
<li>getting a <a href="http://www.clarin.eu/content/persistent-identifiers">PID</a> (Persistent IDentifier) for the corpus</li>
<li>providing the metadata in <a href="http://www.clarin.eu/node/3219">CMDI</a> format</li>
<li>depositing the data and the metadata in a <a href="http://www.clarin.eu/content/depositing-services">repository</a></li>
<li>making it harvestable by the <a href="http://www.clarin.eu/content/virtual-language-observatory">VLO</a></li>
<li>aggregating it to the <a href="http://weblicht.sfs.uni-tuebingen.de/Aggregator/">FCS</a></li>
</ul>
<p>The Universität des Saarlandes as a CLARIN Centre B has the staff and the resources to help you <em>clarinify</em> your data. Check <a href="http://fedora.clarin-d.uni-saarland.de/depositors.en.html">how to deposit data in our repository</a>.</p>
<p>Afterwards, your data will be like SaCoCo:</p>
<ul>
<li>deposited in a DSA awarded <a href="http://fedora.clarin-d.uni-saarland.de/index.en.html">repository</a></li>
<li>findable in the <a href="https://vlo.clarin.eu/search?2&amp;q=sacoco">VLO</a></li>
<li>searchable through <a href="http://weblicht.sfs.uni-tuebingen.de/Aggregator/">Federated Content Search</a></li>
<li>citable thanks to its PID <a href="http://hdl.handle.net/11858/00-246C-0000-001F-7C43-1">hdl:11858/00-246C-0000-001F-7C6F-1</a></li>
</ul>
</div>
</div>
<div id="corpus-exploitation" class="section level1">
<h1>Corpus exploitation</h1>
<p>Our diachronic corpus of cooking recipes in German is now ready to be used. We will proceed as follows:</p>
<ol style="list-style-type: decimal">
<li>We will pose our research question.</li>
<li>We will design the operationalisation of this research question.</li>
<li>We will actually extract the features with CQPweb.</li>
<li>We will visualize and analyse the data with CQPweb/R.</li>
</ol>
<p>If you want to reproduce every step that we will show you below, you will need to get a user for our <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb">CQPweb installation</a>.</p>
<p>Go to this <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/usr/?thisQ=create&amp;uT=y">URL</a> to create a new account. Follow the instructions, and you will have access to SaCoCo in a few minutes.</p>
<div id="research-question" class="section level2">
<h2>Research question</h2>
<blockquote>
<p>Has the realisation of the conative function evolved along the time in the cooking recipe register?</p>
</blockquote>
<p>Our hypothesis is:</p>
<blockquote>
<p>Contemporary cooking recipes show lower linguistic means to address directly to the reader than historical ones.</p>
</blockquote>
<p>Wurm already discovered that historical texts showed differences in the way the author addressed the reader.</p>
</div>
<div id="operationalisation" class="section level2">
<h2>Operationalisation</h2>
<blockquote>
<p>In research design, […] operationalization is a process of defining the measurement of a phenomenon that is not directly measurable, though its existence is indicated by other phenomena.</p>
</blockquote>
<p>We know that German can use different means to convey the conative function. Among them we can trace pronominal and verbal cues:</p>
<ul>
<li>pronominal
<ul>
<li>second person personal pronouns (direct)</li>
<li>indefinite pronouns (indirect)</li>
</ul></li>
<li>verbal
<ul>
<li>imperatives (direct)</li>
<li>infinitives (indirect)</li>
</ul></li>
</ul>
<p>Of course, there are more features that could help us to describe better this phenomenon. Can you think of them? How would you operationalise them? Contributions to extend this tutorial are welcome!!!</p>
<p>The next step is to design how we can retrieve this features in a systematic and effective way making use of the linguistic annotation that we have added with WebLicht.</p>
<p>Basically, we will quantify how many instances of these features can be found per text. First, we need to find the instances, then, we will count them. And, finally, we will describe the results and check if the historical recipes significantly differ from their contemporary counterparts.</p>
<div id="personal-pronouns" class="section level3">
<h3>Personal pronouns</h3>
<p>Second person pronouns are a pronominal indicator of the overt intentions of the writer to engage directly with the reader.</p>
<ul>
<li><em>irreflexives Personalpronomen</em></li>
<li><em>substituirendes Possessivpronomen</em></li>
<li><em>attribuirendes Possessivpronomen</em></li>
<li><em>reflexives Personalpronomen</em></li>
</ul>
</div>
<div id="indefinite-pronouns" class="section level3">
<h3>Indefinite pronouns</h3>
<p>Indefinite pronouns like <em>man</em>, <em>jemand</em>, etc. are a pronominal resource that writers can use to avoid addressing directly to the reader, but still use active voice forms.</p>
<ul>
<li><em>substituierendes Indefinitpronomen</em></li>
</ul>
</div>
<div id="imperatives" class="section level3">
<h3>Imperatives</h3>
<p>The imperative is a verbal device that addresses directly to the reader, it is an order.</p>
<ul>
<li><em>Imperativ</em></li>
</ul>
</div>
<div id="infinitives" class="section level3">
<h3>Infinitives</h3>
<p>The usage of infinitives is a strategy to convey verbal instructions without using the imperative in a more impersonal fashion.</p>
<ul>
<li><em>Infinitiv</em></li>
</ul>
</div>
</div>
<div id="feature-extraction" class="section level2">
<h2>Feature extraction</h2>
<p>OK, we know what we are looking for. Let’s see how.</p>
<p>The CWB comes with a query language that enables the interrogation of large text collections using linguistic patterns to retrieve relevant information. We will use it to find the different features that we have discussed above.</p>
<p>Our next mission is to define the queries that will allow us to find in our corpus the phenomena discussed above.</p>
<div id="queries" class="section level3">
<h3>Queries</h3>
<p>CQP is a corpus query language which resembles to regular expressions, in the sense that one can define patterns aimed at capturing interesting information. The difference here is that we are not limited to write patterns only relying on word forms. We can combine any linguistic information like lemma and POS to construct more sophisticated patterns.</p>
<p>We will illustrate here only the queries used for personal pronouns. If you want to check all of them see file <code>sacoco.cqp</code>.</p>
<div id="personal-pronouns-1" class="section level4">
<h4>Personal pronouns</h4>
<p>This macro is aimed at finding personal pronouns, second person. We will look for:</p>
<ul>
<li>personal pronouns, second person</li>
<li>possessive pronouns, second person</li>
<li>reflexive pronouns</li>
</ul>
<div id="personal-pronouns-second-person" class="section level5">
<h5>Personal pronouns second person</h5>
<ul>
<li>personal pronouns second person singular</li>
<li>personal pronouns second person singular appended to a verbal form</li>
<li>personal pronouns second person plural</li>
</ul>
<p>This query aims at finding second person singular personal pronouns. We know that second person singular is a token whose lemma is <code>du</code>, and its PoS tag is <code>PPER</code>, or a token whose surface form can be <code>du</code>, <code>Du</code>, <code>tu</code>, <code>thu</code>, etc.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">(</span>[<span class="ot">lemma=</span><span class="st">&quot;du&quot;</span> <span class="kw">&amp;</span> <span class="ot">pos=</span><span class="st">&quot;PPER&quot;</span>] <span class="kw">|</span> [<span class="ot">word=</span><span class="st">&quot;[d|t]h?u&quot;</span> <span class="kw">%c</span>]<span class="kw">)</span></code></pre></div>
<p>You can check the results at <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jfreteeu&amp;uT=y" class="uri">https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jfreteeu&amp;uT=y</a></p>
<p>This one looks for tokens ending in du/tu/thu…</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">[<span class="ot">word=</span><span class="st">&quot;.+[t|d]h?u&quot;</span> <span class="kw">%c</span>]</code></pre></div>
<p>It returns 35 matches in 24 different texts <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jfsqg6x5&amp;uT=y" class="uri">https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jfsqg6x5&amp;uT=y</a></p>
<p>And, finally, this one just looks for tokens whose lemma is <code>ihr</code> and their PoS is <code>PPER</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash">[<span class="ot">lemma=</span><span class="st">&quot;ihr&quot;</span> <span class="kw">&amp;</span> <span class="ot">pos=</span><span class="st">&quot;PPER&quot;</span>]</code></pre></div>
<p>This turns to be a quite rare phenomenon, just 3 hits in the whole corpus <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jglv8w52&amp;uT=y" class="uri">https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?qname=f0jglv8w52&amp;uT=y</a>.</p>
<p>In order to see the development of the different features, you have to repeat the steps for all features. Below you can see how to explore a combination of the three queries above in CQPweb and how to visualize the results in CQPweb and/or R.</p>
</div>
</div>
</div>
</div>
<div id="exploration-and-visualization" class="section level2 tabset tabset-fade tabset-pills">
<h2>Exploration and visualization</h2>
<div id="cqpweb" class="section level3">
<h3>CQPweb</h3>
<p>Now, let’s get on with it!</p>
<p>First, you will need access to our <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/">CQPweb installation</a>.</p>
<p>Choose the corpus: in our case <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/">SaCoCo</a></p>
<p>Run a query, e.g. <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/concordance.php?theData=%28%28%5Blemma%3D%22du%22+%26+pos%3D%22PPER%22%5D%29+%7C+%5Bword%3D%22%5Bd%7Ct%5Dh%3Fu%22+%25c%5D%29+%7C+%28%5Bword%3D%22.%2B%5Bt%7Cd%5Dh%3Fu%22+%25c%5D%29+%7C+%28%5Blemma%3D%22ihr%22+%26+pos%3D%22PPER%22%5D%29&amp;qmode=cqp&amp;pp=50&amp;del=begin&amp;t=&amp;del=end&amp;uT=y">combining the queries for personal pronouns second person</a></p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">(</span>[<span class="ot">lemma=</span><span class="st">&quot;du&quot;</span> <span class="kw">&amp;</span> <span class="ot">pos=</span><span class="st">&quot;PPER&quot;</span>] <span class="kw">|</span> [<span class="ot">word=</span><span class="st">&quot;[d|t]h?u&quot;</span> <span class="kw">%c</span>]<span class="kw">)</span>
<span class="kw">|</span>
[<span class="ot">word=</span><span class="st">&quot;.+[t|d]h?u&quot;</span> <span class="kw">%c</span>]
<span class="kw">|</span>
[<span class="ot">lemma=</span><span class="st">&quot;ihr&quot;</span> <span class="kw">&amp;</span> <span class="ot">pos=</span><span class="st">&quot;PPER&quot;</span>]</code></pre></div>
<p>The headline above the concordance gives you information on your query, the number of hits, in how many different texts, etc.</p>
<p><strong>You can now explore the results more closely:</strong></p>
<p>Click on one of the instances to <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/context.php?batch=0&amp;qname=f0k6o1vuih&amp;uT=y">get more context</a></p>
<p>Click on the text ID at the beginning of each concordance line to <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/textmeta.php?text=wiki_270173&amp;uT=y">get information about the text</a></p>
<p><strong>Use the powerful post-processing of CQPweb</strong>, which is available as a drop-down-menu in the upper right corner:</p>
<p>Choose “Frequency breakdown” and click “Go” to get a <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/redirect.php?redirect=breakdown&amp;pp=50&amp;qname=f0k6o1vuih&amp;uT=y">frequency list of your query</a></p>
<p>or Choose “Distribution” and click “Go” to get a distribution of the query results across the subcorpora, in our case, the development over time.</p>
<p>either as <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/redirect.php?redirect=distribution&amp;pp=50&amp;qname=f0k6o1vuih&amp;uT=y">“distribution table”</a></p>
<p>or as <a href="https://fedora.clarin-d.uni-saarland.de/cqpweb/sacoco/redirect.php?classification=__all&amp;showDistAs=graph&amp;crosstabsClass=__none&amp;redirect=refreshDistribution&amp;qname=f0k6o1vuih&amp;pp=50&amp;uT=y">“bar chart”</a></p>
</div>
<div id="r" class="section level3">
<h3>R</h3>
<p>So, in the last section we have seen how to use CQPweb to test our queries, improved them, and also save the results.</p>
<p>For reproducibility purposes, and to speed up the process, you can also interact with CQP from the command line.</p>
<p>If you managed to encode the corpus, you can extract all four features (2n person personal pronouns, indefinite pronouns, imperatives, infinitives) with a <code>sacoco.cqp</code>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># create a directory to save the results</span>
<span class="kw">mkdir</span> -p results/
<span class="co"># run the cqp script to get all the extractions</span>
<span class="kw">cqp</span> -c <span class="kw">&lt;</span> sacoco.cqp</code></pre></div>
<p>In CQPweb we can see the result of a query at a time. But what if we want to get different representations?</p>
<p>Well, then you can use R for that. Let’s describe very briefly our corpus and the results.</p>
<div id="corpus-description" class="section level4">
<h4>Corpus description</h4>
<p>We will read the <code>results/meta.csv</code> which is a table where each row is a text, and the columns are from left to right: text ID, collection, period, decade, year, source.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># import library to format output</span>
<span class="kw">library</span>(knitr)
<span class="co"># read metadata</span>
data =<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;results/meta.csv&#39;</span>, <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>,  <span class="dt">encoding =</span> <span class="st">&#39;utf-8&#39;</span>, <span class="dt">header =</span> F, <span class="dt">strip.white =</span> T)
<span class="co"># rename columns</span>
<span class="kw">names</span>(data) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;text_id&#39;</span>,<span class="st">&#39;collection&#39;</span>,<span class="st">&#39;period&#39;</span>,<span class="st">&#39;decade&#39;</span>,<span class="st">&#39;year&#39;</span>,<span class="st">&#39;source&#39;</span>)
<span class="co"># as factors</span>
data$collection =<span class="st"> </span><span class="kw">as.factor</span>(data$collection)
data$period =<span class="st"> </span><span class="kw">as.factor</span>(data$period)
data$decade =<span class="st"> </span><span class="kw">as.factor</span>(data$decade)
data$year =<span class="st"> </span><span class="kw">as.factor</span>(data$year)
data$source =<span class="st"> </span><span class="kw">as.factor</span>(data$source)
<span class="co"># print summary</span>
<span class="kw">summary</span>(data)</code></pre></div>
<pre><code>##          text_id            collection    period         decade    
##  buchinger_1 :   1   contemporary:2033   1550:  63   2010   :2028  
##  buchinger_10:   1   historical  : 434   1600:  90   1680   :  64  
##  buchinger_11:   1                       1650: 154   1670   :  60  
##  buchinger_12:   1                       1700: 120   1700   :  60  
##  buchinger_13:   1                       1750:   3   1570   :  33  
##  buchinger_14:   1                       1800:   4   1560   :  30  
##  (Other)     :2461                       2000:2033   (Other): 192  
##       year                        source    
##  2013   :859   wiki                  :2033  
##  2014   :776   KochvndKellermeisterey:  33  
##  2011   :183   Thieme                :  31  
##  2012   :168   Buchinger             :  30  
##  2010   : 42   Colerus               :  30  
##  1574   : 33   Danckwerth            :  30  
##  (Other):406   (Other)               : 280</code></pre>
<p>Then we read the table for the number of tokens:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># import library to manipulate tables</span>
<span class="kw">library</span>(dplyr)
<span class="co"># we write a function to read CQP output</span>
cqpReader =<span class="st"> </span>function(filename, feature, data){
  <span class="co"># read file</span>
  df =<span class="st"> </span><span class="kw">read.csv</span>(filename, <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>, <span class="dt">encoding =</span> <span class="st">&#39;utf-8&#39;</span>, <span class="dt">header =</span> F, <span class="dt">strip.white =</span> T)
  <span class="co"># count the number of hits per text</span>
  df =<span class="st"> </span><span class="kw">group_by</span>(df, V1) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">feature =</span> <span class="kw">n</span>())
  <span class="co"># rename first column</span>
  <span class="kw">names</span>(df) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;text_id&#39;</span>,feature)
  <span class="co"># merge with the original table</span>
  data =<span class="st"> </span><span class="kw">merge</span>(data,df,<span class="st">&#39;text_id&#39;</span>,<span class="dt">sort=</span>T, <span class="dt">all=</span>T)
}

<span class="co"># read tokens</span>
data =<span class="st"> </span><span class="kw">cqpReader</span>(<span class="st">&#39;results/tokens.csv&#39;</span>, <span class="st">&#39;tokens&#39;</span>, data)
data[<span class="kw">is.na</span>(data)] =<span class="st"> </span><span class="dv">0</span></code></pre></div>
<p>Then, we get an overview of the size of our corpus by collection:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">texts_and_tokens_x_collection =<span class="st"> </span><span class="kw">group_by</span>(data, collection) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">texts =</span> <span class="kw">n</span>(), <span class="dt">tokens =</span> <span class="kw">sum</span>(tokens))
<span class="kw">kable</span>(texts_and_tokens_x_collection, <span class="dt">align =</span> <span class="st">&#39;l&#39;</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">collection</th>
<th align="left">texts</th>
<th align="left">tokens</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">contemporary</td>
<td align="left">2033</td>
<td align="left">388956</td>
</tr>
<tr class="even">
<td align="left">historical</td>
<td align="left">434</td>
<td align="left">42705</td>
</tr>
</tbody>
</table>
<p>By period:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">texts_and_tokens_x_period =<span class="st"> </span><span class="kw">group_by</span>(data, period) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">texts =</span> <span class="kw">n</span>(), <span class="dt">tokens =</span> <span class="kw">sum</span>(tokens))
<span class="kw">kable</span>(texts_and_tokens_x_period, <span class="dt">align =</span> <span class="st">&#39;l&#39;</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">period</th>
<th align="left">texts</th>
<th align="left">tokens</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1550</td>
<td align="left">63</td>
<td align="left">6016</td>
</tr>
<tr class="even">
<td align="left">1600</td>
<td align="left">90</td>
<td align="left">8806</td>
</tr>
<tr class="odd">
<td align="left">1650</td>
<td align="left">154</td>
<td align="left">14708</td>
</tr>
<tr class="even">
<td align="left">1700</td>
<td align="left">120</td>
<td align="left">12154</td>
</tr>
<tr class="odd">
<td align="left">1750</td>
<td align="left">3</td>
<td align="left">655</td>
</tr>
<tr class="even">
<td align="left">1800</td>
<td align="left">4</td>
<td align="left">366</td>
</tr>
<tr class="odd">
<td align="left">2000</td>
<td align="left">2033</td>
<td align="left">388956</td>
</tr>
</tbody>
</table>
<p>By decade:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">texts_and_tokens_x_decade =<span class="st"> </span><span class="kw">group_by</span>(data, decade) %&gt;%<span class="st"> </span><span class="kw">summarise</span>(<span class="dt">texts =</span> <span class="kw">n</span>(), <span class="dt">tokens =</span> <span class="kw">sum</span>(tokens))
<span class="kw">kable</span>(texts_and_tokens_x_decade, <span class="dt">align =</span> <span class="st">&#39;l&#39;</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">decade</th>
<th align="left">texts</th>
<th align="left">tokens</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1560</td>
<td align="left">30</td>
<td align="left">3223</td>
</tr>
<tr class="even">
<td align="left">1570</td>
<td align="left">33</td>
<td align="left">2793</td>
</tr>
<tr class="odd">
<td align="left">1600</td>
<td align="left">30</td>
<td align="left">3703</td>
</tr>
<tr class="even">
<td align="left">1610</td>
<td align="left">30</td>
<td align="left">3689</td>
</tr>
<tr class="odd">
<td align="left">1640</td>
<td align="left">30</td>
<td align="left">1414</td>
</tr>
<tr class="even">
<td align="left">1670</td>
<td align="left">60</td>
<td align="left">6579</td>
</tr>
<tr class="odd">
<td align="left">1680</td>
<td align="left">64</td>
<td align="left">4647</td>
</tr>
<tr class="even">
<td align="left">1690</td>
<td align="left">30</td>
<td align="left">3482</td>
</tr>
<tr class="odd">
<td align="left">1700</td>
<td align="left">60</td>
<td align="left">2925</td>
</tr>
<tr class="even">
<td align="left">1710</td>
<td align="left">30</td>
<td align="left">6511</td>
</tr>
<tr class="odd">
<td align="left">1720</td>
<td align="left">30</td>
<td align="left">2718</td>
</tr>
<tr class="even">
<td align="left">1780</td>
<td align="left">3</td>
<td align="left">655</td>
</tr>
<tr class="odd">
<td align="left">1800</td>
<td align="left">4</td>
<td align="left">366</td>
</tr>
<tr class="even">
<td align="left">2000</td>
<td align="left">5</td>
<td align="left">633</td>
</tr>
<tr class="odd">
<td align="left">2010</td>
<td align="left">2028</td>
<td align="left">388323</td>
</tr>
</tbody>
</table>
<!-- We can show this with CQPweb -->
</div>
<div id="results" class="section level4">
<h4>Results</h4>
<p>We read the file for the personal pronouns:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read personal pronouns</span>
data =<span class="st"> </span><span class="kw">cqpReader</span>(<span class="st">&#39;results/pers2.csv&#39;</span>, <span class="st">&#39;pers2&#39;</span>, data)
<span class="co"># set NA cells to 0</span>
data[<span class="kw">is.na</span>(data)] =<span class="st"> </span><span class="dv">0</span></code></pre></div>
<p>We can know check visually the differences between contemporary and historical recipes grouping the results by period. You probably have seen that samples are not equal in size. For this reason, we also calculated the relative frequency for each group:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load ggplot2 library to plot graphs</span>
<span class="kw">library</span>(ggplot2)
<span class="co"># calculate the relative frequency for pers2</span>
data.rel =<span class="st"> </span><span class="kw">group_by</span>(data, period) %&gt;%<span class="st"> </span><span class="kw">transform</span>(<span class="dt">pers2.rel =</span> (pers2/tokens)*<span class="dv">1000</span> )
<span class="co"># plot lines binding means</span>
<span class="kw">ggplot</span>(<span class="dt">data=</span>data.rel, <span class="kw">aes</span>(<span class="dt">x=</span>period, <span class="dt">y=</span>pers2.rel, <span class="dt">group=</span>period)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;line&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>, <span class="kw">aes</span>(<span class="dt">group =</span> <span class="dv">1</span>)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="kw">aes</span>(<span class="dt">shape =</span> collection, <span class="dt">colour =</span> collection)) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-7-1.png" title="" alt="" width="672" /></p>
<p>We repeat the same procedure for indefinite pronouns:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read indefinite pronouns</span>
data =<span class="st"> </span><span class="kw">cqpReader</span>(<span class="st">&#39;results/pisp.csv&#39;</span>, <span class="st">&#39;pisp&#39;</span>, data)
data[<span class="kw">is.na</span>(data)] =<span class="st"> </span><span class="dv">0</span>
data.rel =<span class="st"> </span><span class="kw">group_by</span>(data, period) %&gt;%<span class="st"> </span><span class="kw">transform</span>(<span class="dt">pisp.rel =</span> (pisp/tokens)*<span class="dv">1000</span> )
<span class="kw">ggplot</span>(<span class="dt">data=</span>data.rel, <span class="kw">aes</span>(<span class="dt">x=</span>period, <span class="dt">y=</span>pisp.rel, <span class="dt">group=</span>period)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;line&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>, <span class="kw">aes</span>(<span class="dt">group =</span> <span class="dv">1</span>)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="kw">aes</span>(<span class="dt">shape =</span> collection, <span class="dt">colour =</span> collection)) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-8-1.png" title="" alt="" width="672" /></p>
<p>Imperatives:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read imperatives</span>
data =<span class="st"> </span><span class="kw">cqpReader</span>(<span class="st">&#39;results/vfimp.csv&#39;</span>, <span class="st">&#39;vfimp&#39;</span>, data)
data[<span class="kw">is.na</span>(data)] =<span class="st"> </span><span class="dv">0</span>
data.rel =<span class="st"> </span><span class="kw">group_by</span>(data, period) %&gt;%<span class="st"> </span><span class="kw">transform</span>(<span class="dt">vfimp.rel =</span> (vfimp/tokens)*<span class="dv">1000</span> )
<span class="kw">ggplot</span>(<span class="dt">data=</span>data.rel, <span class="kw">aes</span>(<span class="dt">x=</span>period, <span class="dt">y=</span>vfimp.rel, <span class="dt">group=</span>period)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;line&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>, <span class="kw">aes</span>(<span class="dt">group =</span> <span class="dv">1</span>)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="kw">aes</span>(<span class="dt">shape =</span> collection, <span class="dt">colour =</span> collection)) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-9-1.png" title="" alt="" width="672" /></p>
<p>And infinitives:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># read infinitives</span>
data =<span class="st"> </span><span class="kw">cqpReader</span>(<span class="st">&#39;results/vfinf.csv&#39;</span>, <span class="st">&#39;vfinf&#39;</span>, data)
data[<span class="kw">is.na</span>(data)] =<span class="st"> </span><span class="dv">0</span>
data.rel =<span class="st"> </span><span class="kw">group_by</span>(data, period) %&gt;%<span class="st"> </span><span class="kw">transform</span>(<span class="dt">vfinf.rel =</span> (vfinf/tokens)*<span class="dv">1000</span> )
<span class="kw">ggplot</span>(<span class="dt">data=</span>data.rel, <span class="kw">aes</span>(<span class="dt">x=</span>period, <span class="dt">y=</span>vfinf.rel, <span class="dt">group=</span>period)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;line&quot;</span>, <span class="dt">linetype =</span> <span class="st">&quot;dotted&quot;</span>, <span class="kw">aes</span>(<span class="dt">group =</span> <span class="dv">1</span>)) +
<span class="st">  </span><span class="kw">stat_summary</span>(<span class="dt">fun.y=</span>mean, <span class="dt">geom=</span><span class="st">&quot;point&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="kw">aes</span>(<span class="dt">shape =</span> collection, <span class="dt">colour =</span> collection)) +
<span class="st">  </span><span class="kw">theme_bw</span>() +
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position=</span><span class="st">&quot;bottom&quot;</span>)</code></pre></div>
<p><img src="index_files/figure-html/unnamed-chunk-10-1.png" title="" alt="" width="672" /></p>
<p>Let’s put all this together to be able to compare better the evolution of this phenomena:</p>
<!-- # Bibliography -->
<div id="refs" class="references">

</div>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://www.staff.uni-giessen.de/gloning/kobu.htm" class="uri">http://www.staff.uni-giessen.de/gloning/kobu.htm</a><a href="#fnref1">↩</a></p></li>
</ol>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
