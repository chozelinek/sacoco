<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Universität des Saarlandes" />

<meta name="date" content="2016-01-29" />

<title>Saarbrücken Cookbook Corpus: a recipe for a diachronic study à la CLARIN-D</title>

<script src="tutorial_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="tutorial_files/bootstrap-3.3.1/css/cerulean.min.css" rel="stylesheet" />
<script src="tutorial_files/bootstrap-3.3.1/js/bootstrap.min.js"></script>
<script src="tutorial_files/bootstrap-3.3.1/shim/html5shiv.min.js"></script>
<script src="tutorial_files/bootstrap-3.3.1/shim/respond.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; background-color: #dddddd; }
td.sourceCode { padding-left: 5px; }
code > span.kw { font-weight: bold; } /* Keyword */
code > span.dt { color: #800000; } /* DataType */
code > span.dv { color: #0000ff; } /* DecVal */
code > span.bn { color: #0000ff; } /* BaseN */
code > span.fl { color: #800080; } /* Float */
code > span.ch { color: #ff00ff; } /* Char */
code > span.st { color: #dd0000; } /* String */
code > span.co { color: #808080; font-style: italic; } /* Comment */
code > span.al { color: #00ff00; font-weight: bold; } /* Alert */
code > span.fu { color: #000080; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #ff0000; font-weight: bold; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #ff00ff; } /* SpecialChar */
code > span.vs { color: #dd0000; } /* VerbatimString */
code > span.ss { color: #dd0000; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { font-weight: bold; } /* Preprocessor */
code > span.at { } /* Attribute */
code > span.do { color: #808080; font-style: italic; } /* Documentation */
code > span.an { color: #808080; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #808080; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #808080; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>



</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Saarbrücken Cookbook Corpus: a recipe for a diachronic study <em>à la CLARIN-D</em></h1>
<h4 class="author"><em>Universität des Saarlandes</em></h4>
<h4 class="date"><em>29 January 2016</em></h4>
</div>

<div id="TOC">
<ul>
<li><a href="#corpus-compilation"><span class="toc-section-number">1</span> Corpus compilation</a><ul>
<li><a href="#data-acquisition-and-preprocessing"><span class="toc-section-number">1.1</span> Data acquisition and preprocessing</a><ul>
<li><a href="#contemporary-component"><span class="toc-section-number">1.1.1</span> Contemporary component</a></li>
<li><a href="#historical-component"><span class="toc-section-number">1.1.2</span> Historical component</a></li>
</ul></li>
<li><a href="#data-processing-with-weblicht"><span class="toc-section-number">1.2</span> Data processing with WebLicht</a><ul>
<li><a href="#logging-into-weblicht"><span class="toc-section-number">1.2.1</span> Logging into WebLicht</a></li>
<li><a href="#building-the-tool-chain-to-process-contemporary-data"><span class="toc-section-number">1.2.2</span> Building the tool chain to process contemporary data</a></li>
<li><a href="#building-the-tool-chain-to-process-historical-data"><span class="toc-section-number">1.2.3</span> Building the tool chain to process historical data</a></li>
<li><a href="#using-weblicht-as-a-service"><span class="toc-section-number">1.2.4</span> Using WebLicht as a service</a></li>
<li><a href="#processing-the-contemporary-recipes"><span class="toc-section-number">1.2.5</span> Processing the contemporary recipes</a></li>
<li><a href="#processing-the-historical-recipes"><span class="toc-section-number">1.2.6</span> Processing the historical recipes</a></li>
</ul></li>
<li><a href="#corpus-encoding-for-cqpweb"><span class="toc-section-number">1.3</span> Corpus encoding for CQPweb</a><ul>
<li><a href="#add-the-metadata-to-the-vrt-files"><span class="toc-section-number">1.3.1</span> Add the metadata to the VRT files</a></li>
<li><a href="#concatenate-all-texts-in-a-single-corpus-vrt-file"><span class="toc-section-number">1.3.2</span> Concatenate all texts in a single corpus VRT file</a></li>
<li><a href="#encode-the-data-for-cwb"><span class="toc-section-number">1.3.3</span> Encode the data for CWB</a></li>
<li><a href="#set-up-a-corpus-in-cqpweb"><span class="toc-section-number">1.3.4</span> Set up a corpus in CQPweb</a></li>
</ul></li>
<li><a href="#integration-of-the-resource-in-the-clarin-d-infrastructure"><span class="toc-section-number">1.4</span> Integration of the resource in the CLARIN-D infrastructure</a></li>
</ul></li>
<li><a href="#corpus-exploitation"><span class="toc-section-number">2</span> Corpus exploitation</a><ul>
<li><a href="#research-question"><span class="toc-section-number">2.1</span> Research question</a></li>
<li><a href="#operationalisation"><span class="toc-section-number">2.2</span> Operationalisation</a><ul>
<li><a href="#personal-pronouns"><span class="toc-section-number">2.2.1</span> Personal pronouns</a></li>
<li><a href="#indefinite-pronouns"><span class="toc-section-number">2.2.2</span> Indefinite pronouns</a></li>
<li><a href="#imperatives"><span class="toc-section-number">2.2.3</span> Imperatives</a></li>
<li><a href="#infinitives"><span class="toc-section-number">2.2.4</span> Infinitives</a></li>
</ul></li>
<li><a href="#feature-extraction"><span class="toc-section-number">2.3</span> Feature extraction</a><ul>
<li><a href="#queries"><span class="toc-section-number">2.3.1</span> Queries</a></li>
<li><a href="#cqpweb-query-explore-export"><span class="toc-section-number">2.3.2</span> CQPweb: query, explore, export</a></li>
</ul></li>
<li><a href="#visualization-and-analysis-of-results"><span class="toc-section-number">2.4</span> Visualization and analysis of results</a></li>
<li><a href="#corpus-description"><span class="toc-section-number">2.5</span> Corpus description</a></li>
</ul></li>
<li><a href="#bibliography"><span class="toc-section-number">3</span> Bibliography</a></li>
</ul>
</div>

<p><a href="http://hdl.handle.net/11858/00-246C-0000-001F-7C43-1"><img src="tutorial_files/img/sacoco-logo.png" title="Saarbrücken Cookbook Corpus&#39; logo" alt="sacoco logo" /></a></p>
<p>This tutorial will show you step-by-step how to use the CLARIN-D infrastructure to compile a diachronic corpus of German cooking recipes. Afterwards, you will learn how to exploit this resource to discover how the conative function has evolved in this genre during the last centuries.</p>
<p>In order to reproduce succesfully this showcase, you will need to satisfy the following requirements:</p>
<ul>
<li>a UNIX OS</li>
<li>Python 3, and some packages (<code>pip3 install requirements.txt</code>)
<ul>
<li>lxml</li>
<li>pandas</li>
<li>regex</li>
<li>requests</li>
</ul></li>
<li>R</li>
<li>internet connection</li>
</ul>
<p>You also need the materials. Go to our GitHub <a href="https://github.com/chozelinek/sacoco">repo</a> and clone it.</p>
<p>Ready? Steady! Go!</p>
<div id="corpus-compilation" class="section level1">
<h1><span class="header-section-number">1</span> Corpus compilation</h1>
<p>A corpus is a collection of texts in electronic format. We distinguish three main steps in the process of compiling an electronic corpus:</p>
<ol style="list-style-type: decimal">
<li>data acquisition and preprocessing</li>
<li>linguistic annotation with WebLicht</li>
<li>corpus encoding for CQPweb</li>
</ol>
<p>We have two different sources of data:</p>
<ul>
<li>contemporary</li>
<li>historical</li>
</ul>
<p><strong>Historical</strong> recipes were transcribed and digitised manually by Andrea Wurm. Moreover, we completed this dataset with some transcriptions done by Glonning et al. In parallel, we obtained a set of <strong>contemporary</strong> recipes from a wiki site devoted to cooking recipes –<code>rezeptewiki.org</code>, today <a href="http://www.kochwiki.org/wiki/Hauptseite">kochwiki.org</a>. Luckily, a XML dump of this site is available at the <a href="https://archive.org/download/wiki-rezeptewikiorg">Internet Archive</a>.</p>
<p>Due to the different nature of our historical and contemporary datasets. The corpus compilation methodology althoug following a similar outline is slightly different.</p>
<div id="data-acquisition-and-preprocessing" class="section level2">
<h2><span class="header-section-number">1.1</span> Data acquisition and preprocessing</h2>
<p>Our goal at this stage is to obtain the data in digital form. And afterwards, preprocess the material to obtain a homogenous minimalistic TEI/XML format, that we can easily integrate in our pipeline, namely: WebLicht and CQP.</p>
<div id="contemporary-component" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Contemporary component</h3>
<p>Download a wiki dump from <a href="https://archive.org/download/wiki-rezeptewikiorg" class="uri">https://archive.org/download/wiki-rezeptewikiorg</a>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># dowload the dump to the data/contemporary/source folder</span>
<span class="kw">wget</span> -P data/contemporary/source https://archive.org/download/wiki-rezeptewikiorg/rezeptewikiorg-20140325-history.xml.7z
<span class="co"># unzip the file</span>
<span class="kw">7z</span> x -odata/contemporary/source data/contemporary/source/rezeptewikiorg-20140325-history.xml.7z rezeptewikiorg-20140325-history.xml</code></pre></div>
<p>The relatively small 19.8M file becomes a monster of 1.21G. This figure can give you an slight idea of the daunting task of extracting manually information from this file. We use a python script instead (<code>wikiextractor.py</code>) to automatically extract and structure the following information:</p>
<ul>
<li>a minimal <strong>TEI/XML</strong> file for each page containing:
<ul>
<li>title, and</li>
<li>cooking instructions</li>
</ul></li>
<li>a CSV file containing metadata for each page such as:
<ul>
<li>authors</li>
<li>ingredients</li>
<li>tools</li>
<li>methods</li>
<li>cuisines</li>
<li>URL</li>
</ul></li>
</ul>
<p>The input for this script is the huge file <code>rezeptewikiorg-20140325-history.xml</code>. It contains thousands of <code>page</code> nodes, its <code>revision</code>s and the actual <code>text</code>.</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;page&gt;</span>
  <span class="kw">&lt;title&gt;</span><span class="dv">&amp;quot;</span>Krömpele<span class="dv">&amp;quot;</span>-Suppe<span class="kw">&lt;/title&gt;</span>
  <span class="kw">&lt;ns&gt;</span>0<span class="kw">&lt;/ns&gt;</span>
  <span class="kw">&lt;id&gt;</span>46526<span class="kw">&lt;/id&gt;</span>
  <span class="kw">&lt;sha1&gt;</span>rhhwusxi5j205lgcktz71ncz5s12gwu<span class="kw">&lt;/sha1&gt;</span>
  <span class="kw">&lt;revision&gt;</span>
    <span class="kw">&lt;id&gt;</span>262379<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;timestamp&gt;</span>2013-10-30T15:27:50Z<span class="kw">&lt;/timestamp&gt;</span>
    <span class="kw">&lt;contributor&gt;</span>
      <span class="kw">&lt;username&gt;</span>CTHOE<span class="kw">&lt;/username&gt;</span>
      <span class="kw">&lt;id&gt;</span>927<span class="kw">&lt;/id&gt;</span>
    <span class="kw">&lt;/contributor&gt;</span>
    <span class="kw">&lt;comment&gt;</span>Neu angelegt<span class="kw">&lt;/comment&gt;</span>
    <span class="kw">&lt;text</span><span class="ot"> xml:space=</span><span class="st">&quot;preserve&quot;</span><span class="ot"> bytes=</span><span class="st">&quot;1851&quot;</span><span class="kw">&gt;</span>{{Rezept|
 | Menge         = 4 Personen
 | Zeit          = 30–40 Minuten
 | Schwierigkeit = leicht
 | Alkohol       = nein
 | Vegetarisch   = nein
 | Bild          = Kein_Bild.png
|}}

== Zutaten ==
* 175 g [[Zutat:Mehl|Mehl]], gesiebt
* 2–3 [[Zutat:Ei|Eier]]
* 1 Pr. [[Zutat:Salz|Salz]]
* 500 ml [[Zutat:Fleischbrühe|Fleischbrühe]]
* 250 g [[Zutat:Schinkenspeck|Schinkenspeck]]
* frisch geriebener [[Zutat:Muskat|Muskat]]
* 2–3 EL [[Zutat:Schnittlauch|Schnittlauch]]

== Kochgeschirr ==
* 1 [[Zubereitung:Küchenbrett|Küchenbrett]]
* 1 [[Zubereitung:Topf|Topf]]
* 1 [[Zubereitung:Pfanne|Pfanne]]

== Zubereitung ==
* Schnittlauch in kleine Röllchen [[Zubereitung:schneiden|schneiden]]
* Gewürze, Mehl und Eier mit etwas Wasser zu einem dickflüssigen Teig verrühren
* Unter Umständen muss etwas Mehl oder Wasser dazugegeben werden, um die richtige Konsistenz des Teiges zu erreichen
* Den Teig zu großen &#39;&#39;Krömpele&#39;&#39; (Krümel) mit den Händen verreiben
* Etwa 1 l Wasser mit der Brühe [[Zubereitung:aufkochen|aufkochen]]
* Hierin die &#39;&#39;Krömpele&#39;&#39; leicht [[Zubereitung:köcheln|köchelnd]] in etwa 15 Minuten [[Zubereitung:garziehen|garziehen]] lassen
* Zwischenzeitlich den Speck fein [[Zubereitung:würfeln|würfeln]] und goldbraun [[Zubereitung:ausbraten|ausbraten]]
* Speckwürfel in die Suppe schütten, [[Zubereitung:abschmecken|abschmecken]] und mit reichlich Schnittlauchröllchen [[Zubereitung:garnieren|garnieren]] und [[Zubereitung:anrichten|anrichten]]

[[Kategorie:Thüringer Küche]]
[[Kategorie:Nocken]]
[[Kategorie:Vorspeisen]]
[[Kategorie:Suppen]]<span class="kw">&lt;/text&gt;</span>
  <span class="kw">&lt;/revision&gt;</span>
<span class="kw">&lt;/page&gt;</span>  </code></pre></div>
<p>The script does the following:</p>
<ol style="list-style-type: decimal">
<li>opens the input XML file</li>
<li>gets all <code>page</code> nodes</li>
<li>filters those recipes corresponding to German speaking regions only</li>
<li>for each of those recipes gets the last revision</li>
<li>extracts:
<ol style="list-style-type: decimal">
<li>revision ID</li>
<li>page ID</li>
<li>year of last revision</li>
<li>cuisine</li>
<li>authors</li>
<li>ingredients</li>
<li>tools</li>
<li>methods</li>
<li>title</li>
<li>text with the instructions</li>
</ol></li>
<li>title and text are saved as a TEI XML file (<code>data/source/tei</code>)</li>
<li>metadata are saved in a CSV file (<code>data/metadata/wiki-metadata-textid.csv</code>)</li>
</ol>
<p>To run the script you need to run the following commands from the terminal:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># run the script</span>
<span class="kw">python3</span> wikiextractor.py -i data/source/wiki-rezeptewikiorg/rezeptewikiorg-20140325-history.xml -x data/contemporary/tei - data/metadata</code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 wikiextractor.py</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
<p>This is one of the TEI files <code>wiki_188908.xml</code>:</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;?xml-model</span> href=&quot;http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_lite.rng&quot; type=&quot;application/xml&quot; schematypens=&quot;http://relaxng.org/ns/structure/1.0&quot;<span class="kw">?&gt;</span>
<span class="kw">&lt;TEI</span><span class="ot"> xmlns=</span><span class="st">&quot;http://www.tei-c.org/ns/1.0&quot;</span><span class="ot"> xml:lang=</span><span class="st">&quot;de&quot;</span><span class="kw">&gt;</span>
  <span class="kw">&lt;teiHeader&gt;</span>
    <span class="kw">&lt;fileDesc&gt;</span>
      <span class="kw">&lt;titleStmt&gt;</span>
        <span class="kw">&lt;title&gt;</span>Räucherfischmousse im Knusperröllchen auf Gurken-Rahmsalat<span class="kw">&lt;/title&gt;</span>
        <span class="kw">&lt;author&gt;</span>Qualia, Jozeil, NikiWiki<span class="kw">&lt;/author&gt;</span>
        <span class="kw">&lt;respStmt&gt;</span>
          <span class="kw">&lt;resp/&gt;</span>
          <span class="kw">&lt;name/&gt;</span>
        <span class="kw">&lt;/respStmt&gt;</span>
      <span class="kw">&lt;/titleStmt&gt;</span>
      <span class="kw">&lt;publicationStmt&gt;</span>
        <span class="kw">&lt;publisher&gt;</span>Universität des Saarlandes<span class="kw">&lt;/publisher&gt;</span>
        <span class="kw">&lt;pubPlace&gt;</span>Saarbrücken<span class="kw">&lt;/pubPlace&gt;</span>
        <span class="kw">&lt;availability</span><span class="ot"> status=</span><span class="st">&quot;free&quot;</span><span class="kw">&gt;</span>
          <span class="kw">&lt;p&gt;</span>Published under a <span class="kw">&lt;ref</span><span class="ot"> target=</span><span class="st">&quot;http://creativecommons.org/licenses/by-sa/3.0/&quot;</span><span class="kw">&gt;</span>Creative Commons Attribution ShareAlike 3.0 License<span class="kw">&lt;/ref&gt;</span>.<span class="kw">&lt;/p&gt;</span>
        <span class="kw">&lt;/availability&gt;</span>
        <span class="kw">&lt;date&gt;</span>2016<span class="kw">&lt;/date&gt;</span>
      <span class="kw">&lt;/publicationStmt&gt;</span>
      <span class="kw">&lt;sourceDesc&gt;</span>
        <span class="kw">&lt;p&gt;</span>http://www.kochwiki.org/w/index.php?oldid=188908<span class="kw">&lt;/p&gt;</span>
      <span class="kw">&lt;/sourceDesc&gt;</span>
    <span class="kw">&lt;/fileDesc&gt;</span>
  <span class="kw">&lt;/teiHeader&gt;</span>
  <span class="kw">&lt;text</span><span class="ot"> xml:id=</span><span class="st">&quot;wiki_188908&quot;</span><span class="kw">&gt;</span>
    <span class="kw">&lt;body&gt;</span>
      <span class="kw">&lt;div</span><span class="ot"> n=</span><span class="st">&quot;1&quot;</span><span class="ot"> type=</span><span class="st">&quot;recipe&quot;</span><span class="kw">&gt;</span>
        <span class="kw">&lt;head&gt;</span>Räucherfischmousse im Knusperröllchen auf Gurken-Rahmsalat<span class="kw">&lt;/head&gt;</span>
        <span class="kw">&lt;div</span><span class="ot"> n=</span><span class="st">&quot;2&quot;</span><span class="ot"> type=</span><span class="st">&quot;contents&quot;</span><span class="kw">&gt;</span>
          <span class="kw">&lt;head&gt;</span>Räucherfischmousse<span class="kw">&lt;/head&gt;</span>
          <span class="kw">&lt;p&gt;</span>Das Saiblingsfilet entgräten und in grobe Stücke schneiden. Den Fischfond in einem Topf aufkochen. Die Speisestärke in wenig Wasser glatt rühren, den Fond damit abbinden und auskühlen lassen. Dann die Flüssigkeit mit den Räucherfischstücken in den Mixaufsatz der Küchenmaschine füllen und pürieren &quot;(Falls kein Mixaufsatz oder Küchenmaschine vorhanden einen Zauberstab verwenden)&quot;. Die Gelatine in kaltem Wasser einweichen. Einen Topf mit zwei EL Wasser erwärmen und die gut ausgedrückte Gelatine darin auflösen. Während dessen die Schlagsahne halb fest aufschlagen. Die Fischmasse in eine Schüssel füllen und mit der Gelatine sowie etwa der Hälfte des Schlagobers gut vermengen. Dann die restliche Schlagsahne locker unterheben. Das Räucherfischmousse mit Salz sowie Pfeffer abschmecken. Die fertige Fischfüllung mit Klarsichtfolie abdecken und für mindestens 1/2 Stunde im Kühlschrank kalt stellen.<span class="kw">&lt;/p&gt;</span>
        <span class="kw">&lt;/div&gt;</span>
        ...
      <span class="kw">&lt;/div&gt;</span>
    <span class="kw">&lt;/body&gt;</span>
  <span class="kw">&lt;/text&gt;</span>
<span class="kw">&lt;/TEI&gt;</span></code></pre></div>
<p>And this is just an example of a few instances of the metadata file:</p>
<table style="width:50%;">
<colgroup>
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">source</th>
<th align="left">year</th>
<th align="left">title</th>
<th align="left">authors</th>
<th align="left">categories</th>
<th align="left">ingredients</th>
<th align="left">methods</th>
<th align="left">tools</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">wiki_142256</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Salziger Wähenteig mit saurer Sahne</td>
<td align="left">Vran01, Jozeil</td>
<td align="left">Schweizer Küche</td>
<td align="left">Sahne, Salz, Mehl, Butter</td>
<td align="left"></td>
<td align="left">Schüssel, Küchenwaage, Frischhaltefolie</td>
</tr>
<tr class="even">
<td align="left">wiki_150044</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Punschglasur</td>
<td align="left">Jozeil</td>
<td align="left">Österreichische Küche</td>
<td align="left">Eiweiß, Zucker, Orangensaft, Rum</td>
<td align="left">Glasieren</td>
<td align="left">Schüssel, Schneebesen</td>
</tr>
<tr class="odd">
<td align="left">wiki_158731</td>
<td align="left">wiki</td>
<td align="left">2010</td>
<td align="left">Riebelesuppe</td>
<td align="left">Vran01, Hombre, Jozeil, Daniel Beyer</td>
<td align="left">Schwäbische Küche</td>
<td align="left">Weizenmehl, Brühwürfel, Ei, Salz, Pfeffer, Meersalz</td>
<td align="left">Abschmecken</td>
<td align="left">Schüssel, Topf, Küchenreibe</td>
</tr>
</tbody>
</table>
<p>You can check from the commandline if the TEI files are alright:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in data/contemporary/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
<blockquote>
<p>TIP: for development/testing purposes, just switch the input folder:</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">for</span> <span class="kw">i</span> in test/contemporary/tei/*.xml<span class="kw">;</span> <span class="kw">do</span> <span class="kw">xmllint</span> --noout --relaxng utils/tei_lite.rng <span class="ot">$i</span><span class="kw">;</span> <span class="kw">done</span></code></pre></div>
</div>
<div id="historical-component" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Historical component</h3>
</div>
</div>
<div id="data-processing-with-weblicht" class="section level2">
<h2><span class="header-section-number">1.2</span> Data processing with WebLicht</h2>
<p>In the previous section, we have seen how to <em>shape</em> our data for ulterior stages. Once that we have a homogenous format for both collections, it is time to process the texts with <strong>WebLicht</strong>.</p>
<p>At this point, we still have to work separately with the contemporary and historical collections. In both cases, we will perform these steps:</p>
<ol style="list-style-type: decimal">
<li>design a chain in WebLicht
<ol style="list-style-type: decimal">
<li>authenticate</li>
<li>build a tool chain</li>
</ol></li>
<li>process all recipes with this chain using WaaS
<ol style="list-style-type: decimal">
<li>get an API key for WaaS</li>
<li>use a python wrapper to interact with WebLicht</li>
</ol></li>
</ol>
<div id="logging-into-weblicht" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Logging into WebLicht</h3>
<p>We use the Shibboleth Authentication service to log in WebLicht. We will need an identity from a CLARIN identity provider. If your institution is not such a provider you can request an account from the CLARIN provider.</p>
<ol style="list-style-type: decimal">
<li>Visit the <a href="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/Main_Page">WebLicht Wiki</a>, scroll down to the bottom of the page and click on the blue button to <code>Start WebLicht</code>.</li>
<li>The Shibboleth Authentication service will load. Choose your identity provider (<code>clarin.eu website account</code> if you are using a CLARIN account).</li>
<li>You will be redirected to an institutional page where you have to provide your user and password.</li>
<li>If everything is OK, WebLicht’s welcome page will be loaded.</li>
</ol>
<p>This video prepared by our colleagues at Tübingen precisely illustrate the logging process:</p>
<video width="640" height="360" autobuffer controls preload="auto">
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.mp4" type="video/mp4"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.ogv" type="video/ogg"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/WebLichtLogin.webm" type="video/webm"/>
</video>
<p>If you run into problems, read the <a href="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/index.php/FAQ#Logging_In">FAQ explaining how to loggin into WebLicht</a>.</p>
</div>
<div id="building-the-tool-chain-to-process-contemporary-data" class="section level3">
<h3><span class="header-section-number">1.2.2</span> Building the tool chain to process contemporary data</h3>
<ol style="list-style-type: decimal">
<li>Click on <code>New Chain</code>.</li>
<li>A window will pop-up.</li>
<li>There are 3 input modes: click on the leftmost box where one can read <code>Enter your text here.</code> and paste this contemporary recipe excerpt: <code>Das Mehl in die Schüssel geben (eventuell sieben), in der Mitte eine Mulde eindrücken. Die saure Sahne hinein geben und mit Salz bestreuen.</code></li>
<li>Choose the <code>Document Type</code>: <code>Plain Text</code>.</li>
<li>Choose the <code>Language</code>: <code>German</code>.</li>
<li>Click on OK.</li>
<li>Now, you have to choose a mode: pick <code>Advanced Mode</code>.</li>
<li>Choose the tools:
<ol style="list-style-type: decimal">
<li>Berlin: Plaintext Converter</li>
<li>Berlin: Tokenizer and Sentence</li>
<li>Berlin: Part-of-Speech Tagger</li>
</ol></li>
<li>Click on <code>Run Tools</code></li>
<li>Explore the results</li>
<li>Download the chain by clicking on <code>Download chain</code></li>
<li>Save the XML file as <code>chain_contemporary_deu.xml</code> in the folder <code>../scripts</code> of our repo.</li>
</ol>
<p>If the instructions weren’t clear enough, watch this video explaining how to design a tool chain.</p>
<video width="640" height="360" autobuffer controls preload="auto">
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.mp4" type="video/mp4"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.ogv" type="video/ogg"/>
<source src="http://weblicht.sfs.uni-tuebingen.de/weblichtwiki/extensions/HTML5video/videos/SimpleToolChain.webm" type="video/webm"/>
</video>
</div>
<div id="building-the-tool-chain-to-process-historical-data" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Building the tool chain to process historical data</h3>
<p>The process is exactly the same as we used before.</p>
<ol style="list-style-type: decimal">
<li>Click on <code>New Chain</code>.</li>
<li>A window will pop-up.</li>
<li>There are 3 input modes: click on the leftmost box where one can read <code>Enter your text here.</code> and paste this contemporary recipe excerpt: <code>Das Mehl in die Schüssel geben (eventuell sieben), in der Mitte eine Mulde eindrücken. Die saure Sahne hinein geben und mit Salz bestreuen.</code></li>
<li>Choose the <code>Document Type</code>: <code>Plain Text</code>.</li>
<li>Choose the <code>Language</code>: <code>German</code>.</li>
<li>Click on OK.</li>
<li>Now, you have to choose a mode: pick <code>Advanced Mode</code>.</li>
<li>Choose the tools:
<ol style="list-style-type: decimal">
<li>Berlin: Plaintext Converter</li>
<li>Berlin: Tokenizer and Sentence</li>
<li>Berlin: CAB historical text</li>
</ol></li>
<li>Click on <code>Run Tools</code></li>
<li>Explore the results</li>
<li>Download the chain by clicking on <code>Download chain</code></li>
<li>Save the XML file as <code>chain_historical_deu.xml</code> in the folder <code>../scripts</code> of our repo.</li>
</ol>
</div>
<div id="using-weblicht-as-a-service" class="section level3">
<h3><span class="header-section-number">1.2.4</span> Using WebLicht as a service</h3>
<p>We could process our texts directly through the user-friendly WebLicht GUI. However, we have thousands of recipes to be processed. That would be a formidable amount of time wasted in a repetitive task. Fortunately, WebLicht developers devised <a href="https://weblicht.sfs.uni-tuebingen.de/WaaS/"><strong>WaaS</strong></a>.</p>
<blockquote>
<p>WebLicht as a Service (WaaS) is a REST service that executes WebLicht chains. This allows you to run WebLicht chains from your UNIX shell, scripts, or programs.</p>
</blockquote>
<p>It means that we can write a script to automatize our interaction with WebLicht! (Sigh of relief!)</p>
<p>We need at least two things:</p>
<ol style="list-style-type: decimal">
<li>a WebLicht chain</li>
<li>an API key</li>
</ol>
<p>The first item is already solved. For the second, go to the <a href="https://weblicht.sfs.uni-tuebingen.de/WaaS">WaaS home page</a>, click on the rigthmost menu item at the top of the page called <code>API Key</code>. You will be redirected to the already familiar authentication page, choose your institution (<code>clarin.eu website account</code> for us), provide your credentials and a new page will load. If you hit on the button <code>Generate</code> a long string will appear where it reads <code>Your API key</code>. Copy the key in a safe place.</p>
<p>Time to actually process our XML files with <code>WaaS</code>!</p>
</div>
<div id="processing-the-contemporary-recipes" class="section level3">
<h3><span class="header-section-number">1.2.5</span> Processing the contemporary recipes</h3>
<p>We have created a python script to process the recipes with WaaS (<code>weblichtwrapper.py</code>).</p>
<p>The goal of the script is to process all TEI/XML files in a folder with WebLicht and save the results in VRT files for their ulterior encoding as a corpus for the Corpus WorkBench (CWB).</p>
<p>The input is tipically a folder with the TEI/XML files we created in previous sections. But in fact we could use any XML file.</p>
<p>The script does the following:</p>
<ol style="list-style-type: decimal">
<li>obtention of a list of all files to be transformed</li>
<li>find all nodes containing text to be processed</li>
<li>send to WaaS a request to process the text of a node with the provided chain</li>
<li>convert the WaaS response in TCF format to VRT</li>
<li>saves the VRT files in the target directorys</li>
</ol>
<p>To run the script you need to invoke the following commands from the terminal</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> weblichtwrapper.py -i data/contemporary/tei -c utils/chain_contemporary.xml -o data/contemporary/vrt</code></pre></div>
<p>Then, you will be prompted to provide your API key.</p>
<blockquote>
<p>TIP: for development/testing purposes, if you just run <code>python3 weblichtwrapper.py -c chain_contemporary</code>, it will work on the testing dataset stored in the <code>test</code> folder.</p>
</blockquote>
<p>You can get more information on the parameters this script takes by running:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> weblichtwrapper.py -h</code></pre></div>
<p>The output is a VRT file (one token per line and positional attributes separated by a tabulation).</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;text</span><span class="ot"> id=</span><span class="st">&quot;wiki_244969&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;p&gt;</span>
<span class="kw">&lt;s&gt;</span>
Das ART d
Brot    NN  Brot
in  APPR    in
ca. ADV ca.
1   CARD    1
cm  NN  Cm
große   ADJA    groß
Würfel  NN  Würfel
schneiden   VVFIN   schneiden
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;s&gt;</span>
Die ART d
Sonnenblumenkerne   NN  Sonnenblumenkern
in  APPR    in
einer   ART eine
Pfanne  NN  Pfanne
ohne    APPR    ohne
Öl  NN  Öl
anrösten    VVINF   anrösten
und KON und
fein    ADJD    fein
reiben  VVINF   reiben
.   $.  .
<span class="kw">&lt;/s&gt;</span>
...
<span class="kw">&lt;s&gt;</span>
Mit APPR    mit
Sonnenblumenkernen  NN  Sonnenblumenkern
,   $,  ,
Stachelbeeren   NN  Stachelbeere
sowie   KON sowie
Minze   NN  Minze
garnieren   VVINF   garnieren
und KON und
heiß    ADJD    heiß
servieren   VVINF   servieren
.   $.  .
<span class="kw">&lt;/s&gt;</span>
<span class="kw">&lt;/p&gt;</span>
<span class="kw">&lt;/text&gt;</span></code></pre></div>
</div>
<div id="processing-the-historical-recipes" class="section level3">
<h3><span class="header-section-number">1.2.6</span> Processing the historical recipes</h3>
<p>The procedure is exactly the same, the only differences are: the location of the input files, and the chain to be used.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python</span> weblichtwrapper.py -i ../data/source/xml/ -c chain_historical_deu.xml</code></pre></div>
</div>
</div>
<div id="corpus-encoding-for-cqpweb" class="section level2">
<h2><span class="header-section-number">1.3</span> Corpus encoding for CQPweb</h2>
<p>We are going to encode our corpus for the <a href="http://cwb.sourceforge.net">IMS Open Corpus WorkBench</a> (a tool initially developed at IMS Stuttgart). This tool will allow us to query the corpus making the most of the annotation we have obtained with WebLicht.</p>
<p>The CWB expects XML files where two kind of attributes can be added:</p>
<ul>
<li>structural (equivalent to XML attributes, and they affect to regions of tokens)</li>
<li>positional, to add multiple layers of information at token level</li>
</ul>
<p>In the previous section we created the VRT files with the required positional information. Now, we will complete the annotation by adding structural attributes to the text element from the metadata we stored in a CSV file.</p>
<div id="add-the-metadata-to-the-vrt-files" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Add the metadata to the VRT files</h3>
<p>To add the metadata as structural attributes we need:</p>
<ul>
<li>VRT files</li>
<li>metadata as CSV</li>
<li>a script</li>
</ul>
<p>We use <code>addmetadata.py</code> Python script by running the following command:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python3</span> addmetadata.py -i data/contemporary/vrt -m data/metadata/sacoco-metadata.csv -o data/contemporary/meta</code></pre></div>
<p>The script does the following:</p>
<ol style="list-style-type: decimal">
<li>obtention of a list of all files to be transformed</li>
<li>parsing of the metadata</li>
<li>finding all nodes where the metadata fields will be added as attributes</li>
<li>adding to each node its corresponding metadata using the <code>text id</code> as key</li>
<li>saving the VRT files in the target directory</li>
</ol>
<p>We should see something like this:</p>
<div class="sourceCode"><pre class="sourceCode xml"><code class="sourceCode xml"><span class="kw">&lt;?xml</span> version=&#39;1.0&#39; encoding=&#39;UTF8&#39;<span class="kw">?&gt;</span>
<span class="kw">&lt;text</span><span class="ot"> id=</span><span class="st">&quot;wiki_200141&quot;</span><span class="ot"> year=</span><span class="st">&quot;2011&quot;</span><span class="ot"> period=</span><span class="st">&quot;2000&quot;</span><span class="ot"> authors=</span><span class="st">&quot;NikiWiki|Hombre|Jozeil&quot;</span><span class="ot"> decade=</span><span class="st">&quot;2010&quot;</span><span class="ot"> title=</span><span class="st">&quot;Bärlauchnockerl&quot;</span><span class="ot"> methods=</span><span class="st">&quot;hacken|Abschmecken|anrichten&quot;</span><span class="ot"> ingredients=</span><span class="st">&quot;Muskatnuss|Pfeffer|Sauerrahm|Salz|Schmand|Bärlauch|Gelatine&quot;</span><span class="ot"> collection=</span><span class="st">&quot;contemporary&quot;</span><span class="ot"> cuisines=</span><span class="st">&quot;Oberösterreichische Küche&quot;</span><span class="ot"> source=</span><span class="st">&quot;wiki&quot;</span><span class="ot"> tools=</span><span class="st">&quot;Küchenreibe|Schlagkessel|Schüssel|Frischhaltefolie|Schneidebrett|Löffel|Messer|Zauberstab|Küchenmaschine&quot;</span><span class="kw">&gt;</span>
<span class="kw">&lt;p&gt;</span>
<span class="kw">&lt;s&gt;</span>
Den ART d
Bärlauch    NN  Bärlauch
fein    ADJD    fein
hacken  VVINF   hacken
.   $.  .
<span class="kw">&lt;/s&gt;</span>
...
<span class="kw">&lt;/p&gt;</span>
<span class="kw">&lt;/text&gt;</span></code></pre></div>
</div>
<div id="concatenate-all-texts-in-a-single-corpus-vrt-file" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Concatenate all texts in a single corpus VRT file</h3>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">texts2corpus.py</span> -i data/contemporary/meta -o data/sacoco.vrt</code></pre></div>
</div>
<div id="encode-the-data-for-cwb" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Encode the data for CWB</h3>
<p>Once we have the texts in VRT format, encoding the corpus for the CWB is relatively easy.</p>
<p>Check that you have the corpus work bench installed in the computer, if not, download it and follow these <a href="http://cwb.sourceforge.net/download.php">instructions</a>. We compiled from source version 3.4.8.</p>
<p>Now, run the following command:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co"># create the target folder for encoded data</span>
<span class="kw">mkdir</span> -p ../data/encoded/sacoco/data
<span class="co"># run the command</span>
<span class="kw">cwb-encode</span> -c utf8 -d ../data/encoded/sacoco/data -F ../data/source/vrt/ -R ../data/encoded/sacoco/sacoco -xsB -S text:0+id+collection+source+url+year+decade+period+title+authors/+cuisine/+ingredients/+methods/+tools/ -S p:0 -S s:0 -P pos -P lemma -P norm
<span class="co"># generate the registry file</span>
<span class="kw">cwb-make</span> -r ../data/encoded/sacoco -V SACOCO</code></pre></div>
<p>The <code>cwb-encode</code>’s parameters explained:</p>
<ul>
<li><code>-c</code> to the declare the character encoding</li>
<li><code>-d</code> path to the target directory were the output will be stored</li>
<li><code>-F</code> path to the input directory were the VRT files are located</li>
<li><code>-R</code> path to the registry file</li>
<li><code>-xSB</code>
<ul>
<li><code>x</code></li>
<li><code>S</code></li>
<li><code>B</code></li>
</ul></li>
<li><code>-S</code> to declare a structural attribute, example:
<ul>
<li><code>-S text:0+id+authors/</code></li>
<li><code>text</code>, structural attribute to be declared</li>
<li><code>0</code> embedding levels</li>
<li><code>id</code> will be an attribute of <code>text</code> containing some value</li>
<li><code>authors/</code> is also an attribute of <code>text</code> but the slash tells <code>cqp</code> to treate it as a feature set.</li>
</ul></li>
<li><code>-P</code> to declare positional attributes</li>
</ul>
<p>Get extensive information on how to encode corpora for the CWB in the <a href="http://cwb.sourceforge.net/files/CWB_Encoding_Tutorial.pdf">encoding tutorial</a>.</p>
</div>
<div id="set-up-a-corpus-in-cqpweb" class="section level3">
<h3><span class="header-section-number">1.3.4</span> Set up a corpus in CQPweb</h3>
<p>Setting up the corpus for the CQPweb is probably the most involved step described in this tutorial. It is difficult to provide a step-by-step guide, because many things will depend on the server configuration where your CQPweb installation is living. Nevertheless, we provide our procedure below.</p>
<p>There are basically two ways to install a corpus in CQPweb</p>
<ul>
<li>by encoding the corpus directly in CQPweb</li>
<li>by uploading an already encoded corpus and its registry file</li>
</ul>
<p>You need:</p>
<ul>
<li>a corpus encoded for CQP + registry file</li>
<li>a metadata file (optional, but very useful!)</li>
</ul>
<div id="the-meta-data-file" class="section level4">
<h4><span class="header-section-number">1.3.4.1</span> The meta-data file</h4>
<p>The meta-data file is a tab-deliminated file listing categories for each text included in the corpus. These categories can later be used in CQPweb for frequency distribution, etc. It can easily be generated using cqp (see below). An example meta-data file for {{:resources:tools-howtos:dass.txt|DaSciTex-Small}}.</p>
<ul>
<li>the first column is reserved for the text_id</li>
<li>the only category that must have a correspondence in the encoded corpus</li>
<li>values are //handles// and may only include the following characters:</li>
<li>besides, there is no limit to type and number of categories</li>
<li>they do not need a corresponding structure annotated in the corpus!</li>
<li>values do not have to follow the standards for //handles//, but only those that do can be used in the distribution function!</li>
<li>metadata encoded as feature sets cannot be described as “Classification” but as “Free text” because the “|” is not a valid character.</li>
</ul>
<p>You can generate a meta-data file from a CQP corpus using the cqp command-line tool:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">&lt;text&gt;</span>[]<span class="kw">;</span>
<span class="kw">tabulate</span> Last match text_id, match text_..., ... <span class="kw">&gt;</span><span class="st">&quot;corpus.meta&quot;</span><span class="kw">;</span></code></pre></div>
</div>
<div id="upload-files" class="section level4">
<h4><span class="header-section-number">1.3.4.2</span> Upload files</h4>
<p>There are basically two possibilities:</p>
<ul>
<li>via CQPweb Interface -&gt; needs superuser rights on CQPweb;
<ul>
<li>recommended if you have only a few files to upload</li>
<li>you can only upload one file at a time -&gt; this makes it rather undesirable to upload an encoded corpus including a whole bunch of files . Zip or tar files (of whole directories) can be uploaded but not decompressed.</li>
</ul></li>
<li>via ssh -&gt; needs root rights on the underlying server;
<ul>
<li>recommended if you have a whole set of files to upload</li>
</ul></li>
</ul>
<div id="upload-via-cqpweb" class="section level5">
<h5><span class="header-section-number">1.3.4.2.1</span> Upload via CQPweb</h5>
<ul>
<li>concatenate all XML texts using the cat command</li>
</ul>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">cat</span> *.vrt <span class="kw">&gt;</span> ../</code></pre></div>
<ul>
<li>CQPweb Sysadmin Control Panel -&gt; Uploads -&gt; Upload a file</li>
<li>follow the instructions</li>
</ul>
</div>
<div id="upload-via-ssh" class="section level5">
<h5><span class="header-section-number">1.3.4.2.2</span> Upload via ssh</h5>
<ul>
<li>needs root permission on the server</li>
<li>directory for encoded corpora: /data2/cqpweb/indexed</li>
<li>registry directory: /data2/cqpweb/registry</li>
<li>once you uploaded all necessary file make sure that the permissions are as follows:
<ul>
<li>owner: wwwrun</li>
<li>group: www</li>
</ul></li>
<li>make sure that the registry-file has the correct path!!</li>
</ul>
</div>
</div>
<div id="installing-the-corpus" class="section level4">
<h4><span class="header-section-number">1.3.4.3</span> Installing the corpus</h4>
<ul>
<li>CQPweb Sysadmin Control Panel -&gt; Corpora -&gt; Install a new corpus</li>
<li>follow the instructions</li>
<li>The syntax for s-attributes is the same as on the command line: e.g. struc:0+feat1+feat2 (ignore the error message!!!)</li>
<li>certain attributes are annotated automatically and do not have to be specified (see instructions in the form)</li>
</ul>
<div id="installing-an-already-encoded-corpus" class="section level5">
<h5><span class="header-section-number">1.3.4.3.1</span> Installing an already encoded corpus</h5>
<ul>
<li>now you are ready to install the corpus via CQPweb</li>
<li>Click on the link for corpora already indexed in CWB and follow the instructions</li>
<li>after successfully installing the corpus, you may want to use some of the Admin tools to adjust a few settings for the corpus</li>
</ul>
</div>
</div>
<div id="admin-tools" class="section level4">
<h4><span class="header-section-number">1.3.4.4</span> Admin tools</h4>
<ul>
<li>Corpus settings: probably nothing to do here; has been set during the installation process</li>
<li>Manage access: to add user groups for your corpus (otherwise only the superuser can access the corpus!)</li>
<li>Manage metadata: probably nothing to do here; has been set during the installation process</li>
<li>Manage text categories: here you can add more “speaking” descriptions for your text categories</li>
<li>Manage annotation: add descriptions / URLs of documentations for your positional attributes; specify primary/secondary/… annotations for the CQP Simple Query language; specifying annotations here makes them available for restrictions throughout CQPweb (e.g. for the collocation function)</li>
<li>Manage priviliges: Scroll to end of page and generate default privileges for the corpus; select than “Manage group grants”, scroll to end of page and select a group and grant it privileges of that particular corpus (normally normal privileges are choosen)</li>
</ul>
</div>
</div>
</div>
<div id="integration-of-the-resource-in-the-clarin-d-infrastructure" class="section level2">
<h2><span class="header-section-number">1.4</span> Integration of the resource in the CLARIN-D infrastructure</h2>
<p>We have created our resource. Now, we can <em>clarinify</em> it by:</p>
<ul>
<li>getting a <a href="http://www.clarin.eu/content/persistent-identifiers">PID</a> (Persistent IDentifier) for the corpus</li>
<li>providing the metadata in <a href="http://www.clarin.eu/node/3219">CMDI</a> format</li>
<li>depositing the data and the metadata in a <a href="http://www.clarin.eu/content/depositing-services">repository</a></li>
<li>making it harvestable by the <a href="http://www.clarin.eu/content/virtual-language-observatory">VLO</a></li>
<li>aggregating it to the <a href="http://weblicht.sfs.uni-tuebingen.de/Aggregator/">FCS</a></li>
</ul>
<p>The Universität des Saarlandes as a CLARIN Centre B has the staff and the resources to help you <em>clarinify</em> your data. Check <a href="http://fedora.clarin-d.uni-saarland.de/depositors.en.html">how to deposit data in our repository</a>.</p>
<p>Afterwards, your data will be like SaCoCo:</p>
<ul>
<li>deposited in a DSA awarded <a href="http://fedora.clarin-d.uni-saarland.de/index.en.html">repository</a></li>
<li>findable in the <a href="https://vlo.clarin.eu/search?2&amp;q=sacoco">VLO</a></li>
<li>searchable through <a href="http://weblicht.sfs.uni-tuebingen.de/Aggregator/">Federated Content Search</a></li>
<li>citable thanks to its PID <a href="http://hdl.handle.net/11858/00-246C-0000-001F-7C43-1">hdl:11858/00-246C-0000-001F-7C6F-1</a></li>
</ul>
</div>
</div>
<div id="corpus-exploitation" class="section level1">
<h1><span class="header-section-number">2</span> Corpus exploitation</h1>
<p>Our diachronic corpus of cooking recipes in German is now ready to be used. We will proceed as follows:</p>
<ol style="list-style-type: decimal">
<li>We will pose our research question.</li>
<li>We will design the operationalisation of this research question.</li>
<li>We will actually extract the features with CQPweb.</li>
<li>We will visualize and analyse the data with CQPweb/R.</li>
<li>We will describe very briefly our corpus with CQPweb/R.</li>
</ol>
<div id="research-question" class="section level2">
<h2><span class="header-section-number">2.1</span> Research question</h2>
<blockquote>
<p>Has the realisation of the conative function evolved along the time in the cooking recipe register?</p>
</blockquote>
<p>We think that this register has evolved. Our hypothesis is:</p>
<blockquote>
<p>Contemporary cooking recipes show lower linguistic means to address directly to the reader than historical ones.</p>
</blockquote>
</div>
<div id="operationalisation" class="section level2">
<h2><span class="header-section-number">2.2</span> Operationalisation</h2>
<blockquote>
<p>In research design, […] operationalization is a process of defining the measurement of a phenomenon that is not directly measurable, though its existence is indicated by other phenomena.</p>
</blockquote>
<p>We know that German can use different means to convey the conative function. Among them we can trace pronominal and verbal cues:</p>
<ul>
<li>pronominal
<ul>
<li>second person personal pronouns (direct)</li>
<li>indefinite pronouns (indirect)</li>
</ul></li>
<li>verbal
<ul>
<li>imperatives (direct)</li>
<li>infinitives (indirect)</li>
</ul></li>
</ul>
<p>The next step is to design how we can retreive this features in a systematic and effective way making use of the linguistic annotaton we have added with WebLicht.</p>
<p>Basically, we will quantify how many instances of these features we can find per text. Firt, we need to find the instances, then, we will count them. And, finally, we will describe the results and check if historical recipes significantly differ from their contemporary counterparts.</p>
<div id="personal-pronouns" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Personal pronouns</h3>
<p>second person pronouns</p>
<ul>
<li>irreflexives Personalpronomen</li>
<li>substituirendes Possessivpronomen</li>
<li>attribuirendes Possessivpronomen</li>
<li>reflexives Personalpronomen</li>
</ul>
</div>
<div id="indefinite-pronouns" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Indefinite pronouns</h3>
<ul>
<li>substituierendes Indefinitpronomen</li>
</ul>
</div>
<div id="imperatives" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Imperatives</h3>
<ul>
<li>imperatives</li>
</ul>
</div>
<div id="infinitives" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Infinitives</h3>
<ul>
<li>infinitives: VVINF (full verb infinitives), VAINF (auxiliary verb infinitives), VMINF (modal verb infinitives)</li>
</ul>
</div>
</div>
<div id="feature-extraction" class="section level2">
<h2><span class="header-section-number">2.3</span> Feature extraction</h2>
<div id="queries" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Queries</h3>
<!-- queries -->
<!-- macros -->
</div>
<div id="cqpweb-query-explore-export" class="section level3">
<h3><span class="header-section-number">2.3.2</span> CQPweb: query, explore, export</h3>
<!-- step-by-step sequence -->
</div>
</div>
<div id="visualization-and-analysis-of-results" class="section level2">
<h2><span class="header-section-number">2.4</span> Visualization and analysis of results</h2>
<!-- putting all together with R -->
</div>
<div id="corpus-description" class="section level2">
<h2><span class="header-section-number">2.5</span> Corpus description</h2>
<!-- We can show this with CQPweb -->
</div>
</div>
<div id="bibliography" class="section level1">
<h1><span class="header-section-number">3</span> Bibliography</h1>
<p><a href="https://en.wikipedia.org/wiki/Operationalization" class="uri">https://en.wikipedia.org/wiki/Operationalization</a></p>
<div id="refs" class="references">

</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
